{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive sensing example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sigpy.mri as mr\n",
    "\n",
    "import sigpy as sp\n",
    "import sigpy.mri as mr\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "#from models import *\n",
    "#from utils.denoising_utils import *\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_center(img,cropx,cropy):\n",
    "    #y,x = img.shape\n",
    "    y = img.shape[-2]\n",
    "    x = img.shape[-1]\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    if len(img.shape) == 2:\n",
    "        return img[starty:starty+cropy,startx:startx+cropx]\n",
    "    if len(img.shape) == 3:\n",
    "        return img[0,starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "path = './test_data/'\n",
    "img_name = \"poster\"\n",
    "#img_name = \"F16_GT\"\n",
    "#img_name = \"sf4_rgb\"\n",
    "#img_name  = 'library'\n",
    "img_path = path + img_name + \".png\"\n",
    "\n",
    "img_pil = Image.open(img_path)\n",
    "img_np = pil_to_np(img_pil)\n",
    "\n",
    "img_np_small = np.array([crop_center(img_np[0],128,128)])\n",
    "img_var = np_to_var(img_np_small).type(dtype)\n",
    "output_depth = img_np.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_var.view(-1, np.prod(img_var.shape) )\n",
    "n = X.shape[1]\n",
    "m = int(n/3)\n",
    "A = torch.empty(n,m).uniform_(-1, 1).type(dtype)\n",
    "A *= 1/np.sqrt(m)\n",
    "\n",
    "def forwardm(img_var):\n",
    "    X = img_var.view(-1 , np.prod(img_var.shape) ) \n",
    "    return torch.mm(X,A)\n",
    "\n",
    "measurement = forwardm(img_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DD reconstruction and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_input(num_channels,w=128,h=128):\n",
    "    totalupsample = 2**len(num_channels)\n",
    "    width = int(128/totalupsample)\n",
    "    height = int(128/totalupsample)\n",
    "    shape = [1,num_channels[0], width, height]\n",
    "    net_input = Variable(torch.zeros(shape)).type(dtype)\n",
    "    net_input.data.uniform_()\n",
    "    net_input.data *= 1./10\n",
    "    return net_input\n",
    "\n",
    "def get_random_img(num_channels,ni=None):\n",
    "    if ni is None:\n",
    "        ni = get_net_input(num_channels)\n",
    "    net = decodernw(1,num_channels_up=num_channels,need_sigmoid=True).type(dtype)\n",
    "    print(\"generated random image with\", num_channels, \" network has \", num_param(net) )\n",
    "    return net(ni)\n",
    "\n",
    "def myimgshow(plt,img):\n",
    "    if(img.shape[0] == 1):\n",
    "        plt.imshow(np.clip(img[0],0,1),cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(np.clip(img.transpose(1, 2, 0),0,1))\n",
    "    plt.axis('off')    \n",
    "    \n",
    "def plot_img(img_ref): \n",
    "    fig = plt.figure(figsize = (15,15)) # create a 5 x 5 figure   \n",
    "    ax1 = fig.add_subplot(231)\n",
    "    ax1.imshow(img_ref,cmap='gray')\n",
    "    #ax1.set_title('Original image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "def init_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            #m.weight.data.uniform_()\n",
    "            #torch.nn.init.xavier_uniform(m.weight)\n",
    "            #nn.init.uniform_(m.weight)\n",
    "            torch.nn.init.normal_(m.weight)\n",
    "\n",
    "def snr(x_hat,x_true):\n",
    "    x_hat = x_hat.flatten()\n",
    "    x_true = x_true.flatten()\n",
    "    mse= np.sum( np.square(x_hat-x_true) )\n",
    "    #snr_ = 10.*np.log(maxv**2/mse)/np.log(10.)\n",
    "    snr_ = mse / np.sum( np.square(x_true) )\n",
    "    return snr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd_recovery(measurement,img_var,num_channnels,num_iter=6000,apply_f=forwardm,ni=None):\n",
    "    net = decodernw(1,num_channels_up=num_channels,need_sigmoid=True).type(dtype)\n",
    "    #net.apply(init_weights)\n",
    "    mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                                net_input=ni,\n",
    "                        reg_noise_std=0.0,num_iter=num_iter,LR = 0.005,\n",
    "                        img_noisy_var=measurement.type(dtype),\n",
    "                        net=net,apply_f = apply_f,img_clean_var=img_var.type(dtype),\n",
    "                        upsample_mode='bilinear',\n",
    "                        )\n",
    "    print(num_param(net))\n",
    "    out_img_var = net( ni.type(dtype) )\n",
    "    return out_img_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example reconstruction\n",
    "\n",
    "This demonstrates that reconstruction with a deep decoder works well, but a deconvolutional decoder does not enable good reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  [1, 22, 8, 8]\n",
      "optimize with adam 0.005\n",
      "2662ation 05990    Train loss 0.000260  Actual loss 0.000536 Actual loss orig 0.000536 \n"
     ]
    }
   ],
   "source": [
    "k=22\n",
    "num_channels = [k]*4\n",
    "measurement = forwardm(img_var).type(dtype)\n",
    "out_img_var = dd_recovery(measurement,img_var,num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  [1, 6, 4, 4]\n",
      "optimize with adam 0.0025\n",
      "2946ation 04990    Train loss 0.000692  Actual loss 0.003695 Actual loss orig 0.003695 \n"
     ]
    }
   ],
   "source": [
    "def dconv_recovery(img_var):\n",
    "    measurement = forwardm(img_var).type(dtype)\n",
    "    num_channels = [6]*6\n",
    "    net = deconv_decoder(1,num_channels_up=num_channels,filter_size=4,stride=2,padding=1).type(dtype)\n",
    "    mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,num_iter=5000,LR = 0.0025,\n",
    "                        img_noisy_var=measurement,\n",
    "                        net=net,apply_f = forwardm,img_clean_var=img_var.type(dtype),\n",
    "                        upsample_mode='deconv' )\n",
    "    print(num_param(net))\n",
    "    out_img_var = net( ni.type(dtype) )\n",
    "    return out_img_var\n",
    "\n",
    "out_img_dc_var = dconv_recovery(img_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(img_var.data.cpu().numpy()[0,0])\n",
    "#plot_img(out_img_var.data.cpu().numpy()[0,0])\n",
    "#plot_img(out_img_dc_var.data.cpu().numpy()[0,0])\n",
    "\n",
    "def savefig(filename,img):\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "    \n",
    "savefig(img_name + '_orig.png',img_var.data.cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive sensing on random images\n",
    "\n",
    "Our main result shows that taking random linear measurements on the order of the number of parameters of the deep decoder is suffient for recovery is possible. In order to see whether that is also necessary and thus the number of parameters captures the complexity of the range space of the deep decoder, we conduct the following experiment to recover an image in the range of the deep decoder.\n",
    "\n",
    "In order to generate an image, we can in principle simply choose the coefficients of the deep decoder at random. However, for a deep decoder with a fixed number of parameters, this tends to generate simple images, in that often a deep decoder with much fewer coefficients can represent it well. To ensure that we generate a sufficiently complex image, we generate an image in the range of the generator by finding the best representation of noise with the deep decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 198, 395, 786, 1564, 3110, 6186, 12303]\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079273  Actual loss 0.079273 Actual loss orig 0.079273 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000000  Actual loss 0.006793 Actual loss orig 0.006793   \n",
      "error:  0.026771985 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070932  Actual loss 0.070932 Actual loss orig 0.070932 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.059334  Actual loss 0.020901 Actual loss orig 0.020901   \n",
      "error:  0.08020087 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063504  Actual loss 0.063504 Actual loss orig 0.063504 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.211947  Actual loss 0.033879 Actual loss orig 0.033879   \n",
      "error:  0.124778494 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.047454  Actual loss 0.047454 Actual loss orig 0.047454 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.071646  Actual loss 0.052029 Actual loss orig 0.052029   \n",
      "error:  0.18162253 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021438  Actual loss 0.021438 Actual loss orig 0.021438 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.033433  Actual loss 0.098111 Actual loss orig 0.098111   \n",
      "error:  0.30973336 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018943  Actual loss 0.018943 Actual loss orig 0.018943 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000043  Actual loss 0.109936 Actual loss orig 0.109936    \n",
      "error:  0.34770808 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078769  Actual loss 0.078769 Actual loss orig 0.078769 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.001409  Actual loss 0.008264 Actual loss orig 0.008264  \n",
      "error:  0.032289993 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070617  Actual loss 0.070617 Actual loss orig 0.070617 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.010862  Actual loss 0.019906 Actual loss orig 0.019906   \n",
      "error:  0.075739734 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061802  Actual loss 0.061802 Actual loss orig 0.061802 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.011712  Actual loss 0.033920 Actual loss orig 0.033920   \n",
      "error:  0.12472994 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051272  Actual loss 0.051272 Actual loss orig 0.051272 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 1.313929  Actual loss 0.046855 Actual loss orig 0.046855   \n",
      "error:  0.16924873 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023962  Actual loss 0.023962 Actual loss orig 0.023962 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.084905  Actual loss 0.094731 Actual loss orig 0.094731   \n",
      "error:  0.31049532 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019338  Actual loss 0.019338 Actual loss orig 0.019338 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.121195  Actual loss 0.102647 Actual loss orig 0.102647   \n",
      "error:  0.3320237 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078611  Actual loss 0.078611 Actual loss orig 0.078611 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 2.153731  Actual loss 0.009957 Actual loss orig 0.009957  \n",
      "error:  0.03720199 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071285  Actual loss 0.071285 Actual loss orig 0.071285 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000313  Actual loss 0.020145 Actual loss orig 0.020145  \n",
      "error:  0.07760238 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060769  Actual loss 0.060769 Actual loss orig 0.060769 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.030943  Actual loss 0.034378 Actual loss orig 0.034378   \n",
      "error:  0.12914348 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049612  Actual loss 0.049612 Actual loss orig 0.049612 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.074221  Actual loss 0.053267 Actual loss orig 0.053267   \n",
      "error:  0.18507451 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025102  Actual loss 0.025102 Actual loss orig 0.025102 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.101609 Actual loss orig 0.101609   \n",
      "error:  0.32992393 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.245383  Actual loss 0.007892 Actual loss orig 0.007892 \n",
      "error:  0.031548917 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069051  Actual loss 0.069051 Actual loss orig 0.069051 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.163394  Actual loss 0.023081 Actual loss orig 0.023081  \n",
      "error:  0.08773588 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062137  Actual loss 0.062137 Actual loss orig 0.062137 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.004485  Actual loss 0.030086 Actual loss orig 0.030086  \n",
      "error:  0.110828675 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 02990    Train loss 0.052826  Actual loss 0.052826 Actual loss orig 0.052826 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.032019  Actual loss 0.047439 Actual loss orig 0.047439  \n",
      "error:  0.16773193 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021552  Actual loss 0.021552 Actual loss orig 0.021552 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000891  Actual loss 0.101185 Actual loss orig 0.101185   \n",
      "error:  0.33392045 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.021399  Actual loss 0.021399 Actual loss orig 0.021399 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.008689  Actual loss 0.104998 Actual loss orig 0.104998   \n",
      "error:  0.33749205 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079924  Actual loss 0.079924 Actual loss orig 0.079924 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.426384  Actual loss 0.004672 Actual loss orig 0.004672  \n",
      "error:  0.018858531 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.072029  Actual loss 0.072029 Actual loss orig 0.072029 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.649415  Actual loss 0.018916 Actual loss orig 0.018916  \n",
      "error:  0.07070883 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061793  Actual loss 0.061793 Actual loss orig 0.061793 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.443526  Actual loss 0.028713 Actual loss orig 0.028713  \n",
      "error:  0.105482504 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051821  Actual loss 0.051821 Actual loss orig 0.051821 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.001642  Actual loss 0.038231 Actual loss orig 0.038231  \n",
      "error:  0.1340437 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.029243  Actual loss 0.029243 Actual loss orig 0.029243 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.169807  Actual loss 0.077273 Actual loss orig 0.077273  \n",
      "error:  0.26120147 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020452  Actual loss 0.020452 Actual loss orig 0.020452 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000011  Actual loss 0.093507 Actual loss orig 0.093507  \n",
      "error:  0.3023611 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078655  Actual loss 0.078655 Actual loss orig 0.078655 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.080089  Actual loss 0.003877 Actual loss orig 0.003877 \n",
      "error:  0.015227313 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071113  Actual loss 0.071113 Actual loss orig 0.071113 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.820875  Actual loss 0.009627 Actual loss orig 0.009627 \n",
      "error:  0.03623321 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062719  Actual loss 0.062719 Actual loss orig 0.062719 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.313652  Actual loss 0.018299 Actual loss orig 0.018299  \n",
      "error:  0.06849925 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049118  Actual loss 0.049118 Actual loss orig 0.049118 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.102353  Actual loss 0.031004 Actual loss orig 0.031004  \n",
      "error:  0.11010071 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023285  Actual loss 0.023285 Actual loss orig 0.023285 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.005105  Actual loss 0.079028 Actual loss orig 0.079028  \n",
      "error:  0.26096871 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018705  Actual loss 0.018705 Actual loss orig 0.018705 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.008989  Actual loss 0.083509 Actual loss orig 0.083509  \n",
      "error:  0.27059183 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078631  Actual loss 0.078631 Actual loss orig 0.078631 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.552291  Actual loss 0.002835 Actual loss orig 0.002835 \n",
      "error:  0.011224931 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070402  Actual loss 0.070402 Actual loss orig 0.070402 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.765633  Actual loss 0.006967 Actual loss orig 0.006967 \n",
      "error:  0.026613906 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062824  Actual loss 0.062824 Actual loss orig 0.062824 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.627394  Actual loss 0.011316 Actual loss orig 0.011316 \n",
      "error:  0.04166779 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053612  Actual loss 0.053612 Actual loss orig 0.053612 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.278942  Actual loss 0.013845 Actual loss orig 0.013845 \n",
      "error:  0.05062114 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025131  Actual loss 0.025131 Actual loss orig 0.025131 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.046229  Actual loss 0.044984 Actual loss orig 0.044984  \n",
      "error:  0.14662193 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017228  Actual loss 0.017228 Actual loss orig 0.017228 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.006563  Actual loss 0.055406 Actual loss orig 0.055406  \n",
      "error:  0.17636816 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079659  Actual loss 0.079659 Actual loss orig 0.079659 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.286068  Actual loss 0.002507 Actual loss orig 0.002507 \n",
      "error:  0.01008421 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070410  Actual loss 0.070410 Actual loss orig 0.070410 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.416667  Actual loss 0.005065 Actual loss orig 0.005065 \n",
      "error:  0.019045403 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064815  Actual loss 0.064815 Actual loss orig 0.064815 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.407390  Actual loss 0.006775 Actual loss orig 0.006775 \n",
      "error:  0.024626497 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049864  Actual loss 0.049864 Actual loss orig 0.049864 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.343717  Actual loss 0.008530 Actual loss orig 0.008530 \n",
      "error:  0.029431991 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023447  Actual loss 0.023447 Actual loss orig 0.023447 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.392412  Actual loss 0.017936 Actual loss orig 0.017936 \n",
      "error:  0.059109986 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019073  Actual loss 0.019073 Actual loss orig 0.019073 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.244237  Actual loss 0.018671 Actual loss orig 0.018671 \n",
      "error:  0.058875035 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078604  Actual loss 0.078604 Actual loss orig 0.078604 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000000  Actual loss 0.008003 Actual loss orig 0.008003  \n",
      "error:  0.031629812 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071641  Actual loss 0.071641 Actual loss orig 0.071641 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000571  Actual loss 0.018513 Actual loss orig 0.018513   \n",
      "error:  0.07016358 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062483  Actual loss 0.062483 Actual loss orig 0.062483 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000000  Actual loss 0.034270 Actual loss orig 0.034270   \n",
      "error:  0.12461381 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050683  Actual loss 0.050683 Actual loss orig 0.050683 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.002009  Actual loss 0.053162 Actual loss orig 0.053162   \n",
      "error:  0.19208731 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024480  Actual loss 0.024480 Actual loss orig 0.024480 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.468589  Actual loss 0.095453 Actual loss orig 0.095453  1 \n",
      "error:  0.31027338 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018237  Actual loss 0.018237 Actual loss orig 0.018237 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.019354 Actual loss orig 0.019354    \n",
      "error:  0.07309119 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062872  Actual loss 0.062872 Actual loss orig 0.062872 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000343  Actual loss 0.036076 Actual loss orig 0.036076   \n",
      "error:  0.13191846 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049908  Actual loss 0.049908 Actual loss orig 0.049908 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000343  Actual loss 0.054444 Actual loss orig 0.054444   \n",
      "error:  0.18805158 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023965  Actual loss 0.023965 Actual loss orig 0.023965 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.002684  Actual loss 0.087226 Actual loss orig 0.087226   \n",
      "error:  0.28407282 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020563  Actual loss 0.020563 Actual loss orig 0.020563 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000011  Actual loss 0.092861 Actual loss orig 0.092861   \n",
      "error:  0.29605448 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080485  Actual loss 0.080485 Actual loss orig 0.080485 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.154845  Actual loss 0.008050 Actual loss orig 0.008050  \n",
      "error:  0.031882547 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069745  Actual loss 0.069745 Actual loss orig 0.069745 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.006464  Actual loss 0.021508 Actual loss orig 0.021508  \n",
      "error:  0.08204561 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830ation 02990    Train loss 0.064555  Actual loss 0.064555 Actual loss orig 0.064555 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.046866  Actual loss 0.030664 Actual loss orig 0.030664   \n",
      "error:  0.11319579 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052730  Actual loss 0.052730 Actual loss orig 0.052730 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.233089  Actual loss 0.042845 Actual loss orig 0.042845   \n",
      "error:  0.15334797 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025494  Actual loss 0.025494 Actual loss orig 0.025494 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000031  Actual loss 0.084028 Actual loss orig 0.084028   \n",
      "error:  0.27742192 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.021054  Actual loss 0.021054 Actual loss orig 0.021054 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.100570 Actual loss orig 0.100570   \n",
      "error:  0.32368946 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079721  Actual loss 0.079721 Actual loss orig 0.079721 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.134413  Actual loss 0.006710 Actual loss orig 0.006710  \n",
      "error:  0.026741603 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071146  Actual loss 0.071146 Actual loss orig 0.071146 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.031273  Actual loss 0.018972 Actual loss orig 0.018972  \n",
      "error:  0.071614996 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063434  Actual loss 0.063434 Actual loss orig 0.063434 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.002578  Actual loss 0.030128 Actual loss orig 0.030128  \n",
      "error:  0.11135092 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049822  Actual loss 0.049822 Actual loss orig 0.049822 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000000  Actual loss 0.055071 Actual loss orig 0.055071  \n",
      "error:  0.19610952 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025667  Actual loss 0.025667 Actual loss orig 0.025667 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000026  Actual loss 0.086418 Actual loss orig 0.086418   \n",
      "error:  0.28818727 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.021374  Actual loss 0.021374 Actual loss orig 0.021374 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000050  Actual loss 0.108665 Actual loss orig 0.108665   \n",
      "error:  0.34927386 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079994  Actual loss 0.079994 Actual loss orig 0.079994 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.800032  Actual loss 0.004647 Actual loss orig 0.004647  \n",
      "error:  0.018666832 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070431  Actual loss 0.070431 Actual loss orig 0.070431 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.253137  Actual loss 0.018543 Actual loss orig 0.018543  \n",
      "error:  0.07088377 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061471  Actual loss 0.061471 Actual loss orig 0.061471 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.308943  Actual loss 0.028612 Actual loss orig 0.028612  \n",
      "error:  0.105592825 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051797  Actual loss 0.051797 Actual loss orig 0.051797 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.021996  Actual loss 0.036581 Actual loss orig 0.036581  \n",
      "error:  0.13125484 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024286  Actual loss 0.024286 Actual loss orig 0.024286 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.001702  Actual loss 0.089034 Actual loss orig 0.089034  \n",
      "error:  0.29134598 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015341  Actual loss 0.015341 Actual loss orig 0.015341 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.110062 Actual loss orig 0.110062  \n",
      "error:  0.34753188 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080742  Actual loss 0.080742 Actual loss orig 0.080742 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.750525  Actual loss 0.002677 Actual loss orig 0.002677 \n",
      "error:  0.010557755 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069412  Actual loss 0.069412 Actual loss orig 0.069412 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.654144  Actual loss 0.010581 Actual loss orig 0.010581 \n",
      "error:  0.040392723 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062194  Actual loss 0.062194 Actual loss orig 0.062194 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.565909  Actual loss 0.020689 Actual loss orig 0.020689  \n",
      "error:  0.07830864 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050368  Actual loss 0.050368 Actual loss orig 0.050368 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.418217  Actual loss 0.031306 Actual loss orig 0.031306  \n",
      "error:  0.110791676 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023515  Actual loss 0.023515 Actual loss orig 0.023515 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.023326  Actual loss 0.072480 Actual loss orig 0.072480  \n",
      "error:  0.239504 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016915  Actual loss 0.016915 Actual loss orig 0.016915 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.085919  Actual loss 0.089928 Actual loss orig 0.089928  \n",
      "error:  0.28343037 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079742  Actual loss 0.079742 Actual loss orig 0.079742 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.596307  Actual loss 0.003052 Actual loss orig 0.003052 \n",
      "error:  0.011954125 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071981  Actual loss 0.071981 Actual loss orig 0.071981 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.605775  Actual loss 0.005969 Actual loss orig 0.005969 \n",
      "error:  0.02248366 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062238  Actual loss 0.062238 Actual loss orig 0.062238 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.601727  Actual loss 0.011127 Actual loss orig 0.011127 \n",
      "error:  0.040548205 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050800  Actual loss 0.050800 Actual loss orig 0.050800 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.363666  Actual loss 0.018808 Actual loss orig 0.018808  \n",
      "error:  0.07242358 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023914  Actual loss 0.023914 Actual loss orig 0.023914 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.053522  Actual loss 0.043415 Actual loss orig 0.043415  \n",
      "error:  0.14310096 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.014963  Actual loss 0.014963 Actual loss orig 0.014963 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.059241  Actual loss 0.064031 Actual loss orig 0.064031  \n",
      "error:  0.2012069 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079483  Actual loss 0.079483 Actual loss orig 0.079483 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.228751  Actual loss 0.001973 Actual loss orig 0.001973 \n",
      "error:  0.0074972487 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070109  Actual loss 0.070109 Actual loss orig 0.070109 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.433218  Actual loss 0.005316 Actual loss orig 0.005316 \n",
      "error:  0.0206556 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063184  Actual loss 0.063184 Actual loss orig 0.063184 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.499720  Actual loss 0.008071 Actual loss orig 0.008071 \n",
      "error:  0.02877123 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052029  Actual loss 0.052029 Actual loss orig 0.052029 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.358396  Actual loss 0.008244 Actual loss orig 0.008244 \n",
      "error:  0.030973073 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025401  Actual loss 0.025401 Actual loss orig 0.025401 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.213592  Actual loss 0.015597 Actual loss orig 0.015597 \n",
      "error:  0.04866369 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016424  Actual loss 0.016424 Actual loss orig 0.016424 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.201288  Actual loss 0.019186 Actual loss orig 0.019186 \n",
      "error:  0.061220657 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078793  Actual loss 0.078793 Actual loss orig 0.078793 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000018  Actual loss 0.008175 Actual loss orig 0.008175   \n",
      "error:  0.032273326 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070465  Actual loss 0.070465 Actual loss orig 0.070465 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.001427  Actual loss 0.019296 Actual loss orig 0.019296   \n",
      "error:  0.07255564 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061694  Actual loss 0.061694 Actual loss orig 0.061694 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000000  Actual loss 0.033656 Actual loss orig 0.033656   \n",
      "error:  0.12486682 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049470  Actual loss 0.049470 Actual loss orig 0.049470 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000230  Actual loss 0.048708 Actual loss orig 0.048708   \n",
      "error:  0.17346135 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024377  Actual loss 0.024377 Actual loss orig 0.024377 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000804  Actual loss 0.111869 Actual loss orig 0.111869    \n",
      "error:  0.35875383 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315250ion 02990    Train loss 0.016535  Actual loss 0.016535 Actual loss orig 0.016535 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000049  Actual loss 0.123133 Actual loss orig 0.123133    \n",
      "error:  0.39183387 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.077497  Actual loss 0.077497 Actual loss orig 0.077497 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.127357  Actual loss 0.009161 Actual loss orig 0.009161   \n",
      "error:  0.03629667 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070388  Actual loss 0.070388 Actual loss orig 0.070388 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000003  Actual loss 0.018313 Actual loss orig 0.018313   \n",
      "error:  0.06996646 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064055  Actual loss 0.064055 Actual loss orig 0.064055 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.003982  Actual loss 0.029154 Actual loss orig 0.029154   \n",
      "error:  0.109292656 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052200  Actual loss 0.052200 Actual loss orig 0.052200 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.027531  Actual loss 0.050150 Actual loss orig 0.050150   \n",
      "error:  0.17972304 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022540  Actual loss 0.022540 Actual loss orig 0.022540 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000251  Actual loss 0.102034 Actual loss orig 0.102034   \n",
      "error:  0.32511625 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016267  Actual loss 0.016267 Actual loss orig 0.016267 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000760  Actual loss 0.112357 Actual loss orig 0.112357   \n",
      "error:  0.35912636 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080793  Actual loss 0.080793 Actual loss orig 0.080793 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.164615  Actual loss 0.008283 Actual loss orig 0.008283  \n",
      "error:  0.032337785 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069659  Actual loss 0.069659 Actual loss orig 0.069659 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.182774  Actual loss 0.022226 Actual loss orig 0.022226  \n",
      "error:  0.0842615 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061629  Actual loss 0.061629 Actual loss orig 0.061629 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000282  Actual loss 0.034927 Actual loss orig 0.034927   \n",
      "error:  0.12681268 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049936  Actual loss 0.049936 Actual loss orig 0.049936 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000048  Actual loss 0.045801 Actual loss orig 0.045801   \n",
      "error:  0.16587058 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025572  Actual loss 0.025572 Actual loss orig 0.025572 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.031589  Actual loss 0.087555 Actual loss orig 0.087555   \n",
      "error:  0.28328806 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015974  Actual loss 0.015974 Actual loss orig 0.015974 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 1.450685  Actual loss 0.109512 Actual loss orig 0.109512   \n",
      "error:  0.34687325 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078878  Actual loss 0.078878 Actual loss orig 0.078878 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 2.136664  Actual loss 0.007283 Actual loss orig 0.007283  \n",
      "error:  0.028126886 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.074648  Actual loss 0.074648 Actual loss orig 0.074648 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.062179  Actual loss 0.018386 Actual loss orig 0.018386  \n",
      "error:  0.0704999 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062063  Actual loss 0.062063 Actual loss orig 0.062063 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000792  Actual loss 0.033364 Actual loss orig 0.033364  \n",
      "error:  0.1239413 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053313  Actual loss 0.053313 Actual loss orig 0.053313 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000004  Actual loss 0.044788 Actual loss orig 0.044788  \n",
      "error:  0.1601947 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025917  Actual loss 0.025917 Actual loss orig 0.025917 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000045  Actual loss 0.095268 Actual loss orig 0.095268   \n",
      "error:  0.30899268 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017382  Actual loss 0.017382 Actual loss orig 0.017382 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.098485  Actual loss 0.107310 Actual loss orig 0.107310   \n",
      "error:  0.34009412 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078823  Actual loss 0.078823 Actual loss orig 0.078823 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.478243  Actual loss 0.004608 Actual loss orig 0.004608  \n",
      "error:  0.018222544 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.072075  Actual loss 0.072075 Actual loss orig 0.072075 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.311386  Actual loss 0.016453 Actual loss orig 0.016453  \n",
      "error:  0.06299163 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064004  Actual loss 0.064004 Actual loss orig 0.064004 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.034948  Actual loss 0.024587 Actual loss orig 0.024587  \n",
      "error:  0.09318967 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.054151  Actual loss 0.054151 Actual loss orig 0.054151 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.012321  Actual loss 0.040298 Actual loss orig 0.040298  \n",
      "error:  0.14196825 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023089  Actual loss 0.023089 Actual loss orig 0.023089 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.065130  Actual loss 0.097173 Actual loss orig 0.097173  \n",
      "error:  0.31341073 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016409  Actual loss 0.016409 Actual loss orig 0.016409 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.004081  Actual loss 0.103593 Actual loss orig 0.103593  \n",
      "error:  0.32670978 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079660  Actual loss 0.079660 Actual loss orig 0.079660 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.898713  Actual loss 0.003440 Actual loss orig 0.003440 \n",
      "error:  0.013611915 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070776  Actual loss 0.070776 Actual loss orig 0.070776 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.842302  Actual loss 0.011013 Actual loss orig 0.011013 \n",
      "error:  0.041727427 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061077  Actual loss 0.061077 Actual loss orig 0.061077 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.466826  Actual loss 0.021648 Actual loss orig 0.021648  \n",
      "error:  0.07934193 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048068  Actual loss 0.048068 Actual loss orig 0.048068 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.272294  Actual loss 0.034867 Actual loss orig 0.034867  \n",
      "error:  0.123185165 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024155  Actual loss 0.024155 Actual loss orig 0.024155 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.355584  Actual loss 0.073082 Actual loss orig 0.073082  \n",
      "error:  0.23748635 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017681  Actual loss 0.017681 Actual loss orig 0.017681 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.006993  Actual loss 0.088632 Actual loss orig 0.088632  \n",
      "error:  0.27729672 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079714  Actual loss 0.079714 Actual loss orig 0.079714 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.553231  Actual loss 0.002817 Actual loss orig 0.002817 \n",
      "error:  0.010770096 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069480  Actual loss 0.069480 Actual loss orig 0.069480 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.917665  Actual loss 0.008224 Actual loss orig 0.008224 \n",
      "error:  0.03206287 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064024  Actual loss 0.064024 Actual loss orig 0.064024 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.566793  Actual loss 0.010123 Actual loss orig 0.010123 \n",
      "error:  0.0381786 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049034  Actual loss 0.049034 Actual loss orig 0.049034 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.379075  Actual loss 0.016726 Actual loss orig 0.016726 \n",
      "error:  0.06157982 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021107  Actual loss 0.021107 Actual loss orig 0.021107 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.086720  Actual loss 0.051982 Actual loss orig 0.051982  \n",
      "error:  0.16335309 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017480  Actual loss 0.017480 Actual loss orig 0.017480 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 2.049748  Actual loss 0.057086 Actual loss orig 0.057086  \n",
      "error:  0.17807595 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078203  Actual loss 0.078203 Actual loss orig 0.078203 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.306277  Actual loss 0.002680 Actual loss orig 0.002680 \n",
      "error:  0.010461288 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069182  Actual loss 0.069182 Actual loss orig 0.069182 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220ation 09990    Train loss 0.575576  Actual loss 0.006713 Actual loss orig 0.006713 \n",
      "error:  0.02444011 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061888  Actual loss 0.061888 Actual loss orig 0.061888 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.434931  Actual loss 0.007378 Actual loss orig 0.007378 \n",
      "error:  0.029078126 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048203  Actual loss 0.048203 Actual loss orig 0.048203 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.583060  Actual loss 0.010647 Actual loss orig 0.010647 \n",
      "error:  0.031504396 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024839  Actual loss 0.024839 Actual loss orig 0.024839 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.169078  Actual loss 0.014404 Actual loss orig 0.014404 \n",
      "error:  0.052096594 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017020  Actual loss 0.017020 Actual loss orig 0.017020 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.316894  Actual loss 0.021757 Actual loss orig 0.021757 \n",
      "error:  0.06672929 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078812  Actual loss 0.078812 Actual loss orig 0.078812 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000020  Actual loss 0.008620 Actual loss orig 0.008620   \n",
      "error:  0.034169424 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071549  Actual loss 0.071549 Actual loss orig 0.071549 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.021489 Actual loss orig 0.021489   \n",
      "error:  0.08433584 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061044  Actual loss 0.061044 Actual loss orig 0.061044 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.027057  Actual loss 0.036101 Actual loss orig 0.036101   \n",
      "error:  0.13287176 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049672  Actual loss 0.049672 Actual loss orig 0.049672 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.002128  Actual loss 0.048827 Actual loss orig 0.048827   \n",
      "error:  0.1723983 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.026594  Actual loss 0.026594 Actual loss orig 0.026594 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.039859  Actual loss 0.098135 Actual loss orig 0.098135  6 \n",
      "error:  0.31920278 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015787  Actual loss 0.015787 Actual loss orig 0.015787 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000004  Actual loss 0.132125 Actual loss orig 0.132125    \n",
      "error:  0.41854417 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078613  Actual loss 0.078613 Actual loss orig 0.078613 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000128  Actual loss 0.006597 Actual loss orig 0.006597  \n",
      "error:  0.026045466 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069926  Actual loss 0.069926 Actual loss orig 0.069926 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.143804  Actual loss 0.022151 Actual loss orig 0.022151   \n",
      "error:  0.084901765 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061464  Actual loss 0.061464 Actual loss orig 0.061464 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 1.068997  Actual loss 0.034585 Actual loss orig 0.034585   \n",
      "error:  0.12367551 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050078  Actual loss 0.050078 Actual loss orig 0.050078 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000000  Actual loss 0.052745 Actual loss orig 0.052745   \n",
      "error:  0.18480913 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023663  Actual loss 0.023663 Actual loss orig 0.023663 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.106937 Actual loss orig 0.106937   \n",
      "error:  0.3502246 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016985  Actual loss 0.016985 Actual loss orig 0.016985 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000573  Actual loss 0.111908 Actual loss orig 0.111908   \n",
      "error:  0.34896442 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080213  Actual loss 0.080213 Actual loss orig 0.080213 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.152918  Actual loss 0.007737 Actual loss orig 0.007737  \n",
      "error:  0.03057348 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069483  Actual loss 0.069483 Actual loss orig 0.069483 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000020  Actual loss 0.019825 Actual loss orig 0.019825  \n",
      "error:  0.075893484 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060162  Actual loss 0.060162 Actual loss orig 0.060162 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000167  Actual loss 0.036590 Actual loss orig 0.036590   \n",
      "error:  0.13594621 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 02990    Train loss 0.047204  Actual loss 0.047204 Actual loss orig 0.047204 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000000  Actual loss 0.053430 Actual loss orig 0.053430   \n",
      "error:  0.18948771 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.019253  Actual loss 0.019253 Actual loss orig 0.019253 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000399  Actual loss 0.108686 Actual loss orig 0.108686   \n",
      "error:  0.3470813 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018854  Actual loss 0.018854 Actual loss orig 0.018854 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.003091  Actual loss 0.104901 Actual loss orig 0.104901   \n",
      "error:  0.33743066 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078041  Actual loss 0.078041 Actual loss orig 0.078041 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.265582  Actual loss 0.007986 Actual loss orig 0.007986  \n",
      "error:  0.03087319 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071599  Actual loss 0.071599 Actual loss orig 0.071599 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.116304  Actual loss 0.021156 Actual loss orig 0.021156  \n",
      "error:  0.08136729 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062098  Actual loss 0.062098 Actual loss orig 0.062098 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 6.596228  Actual loss 0.026647 Actual loss orig 0.026647  \n",
      "error:  0.10117815 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051466  Actual loss 0.051466 Actual loss orig 0.051466 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000001  Actual loss 0.046520 Actual loss orig 0.046520  \n",
      "error:  0.16375533 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023675  Actual loss 0.023675 Actual loss orig 0.023675 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.004939  Actual loss 0.098156 Actual loss orig 0.098156   \n",
      "error:  0.3180404 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017923  Actual loss 0.017923 Actual loss orig 0.017923 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000625  Actual loss 0.109440 Actual loss orig 0.109440   \n",
      "error:  0.34480816 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078828  Actual loss 0.078828 Actual loss orig 0.078828 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.281624  Actual loss 0.004550 Actual loss orig 0.004550  \n",
      "error:  0.017886566 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069634  Actual loss 0.069634 Actual loss orig 0.069634 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.647719  Actual loss 0.019513 Actual loss orig 0.019513  \n",
      "error:  0.073707044 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061866  Actual loss 0.061866 Actual loss orig 0.061866 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.027379  Actual loss 0.027462 Actual loss orig 0.027462  \n",
      "error:  0.10126027 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052875  Actual loss 0.052875 Actual loss orig 0.052875 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000001  Actual loss 0.039159 Actual loss orig 0.039159  \n",
      "error:  0.13719484 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.027121  Actual loss 0.027121 Actual loss orig 0.027121 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000004  Actual loss 0.079873 Actual loss orig 0.079873  \n",
      "error:  0.25161496 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015294  Actual loss 0.015294 Actual loss orig 0.015294 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.015101  Actual loss 0.109851 Actual loss orig 0.109851  \n",
      "error:  0.3469482 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078281  Actual loss 0.078281 Actual loss orig 0.078281 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.067377  Actual loss 0.003791 Actual loss orig 0.003791  \n",
      "error:  0.015067939 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069269  Actual loss 0.069269 Actual loss orig 0.069269 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.816612  Actual loss 0.011649 Actual loss orig 0.011649  \n",
      "error:  0.04328169 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061898  Actual loss 0.061898 Actual loss orig 0.061898 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.803489  Actual loss 0.019318 Actual loss orig 0.019318  \n",
      "error:  0.07109359 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.054109  Actual loss 0.054109 Actual loss orig 0.054109 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.024270  Actual loss 0.025571 Actual loss orig 0.025571  \n",
      "error:  0.09403304 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.020380  Actual loss 0.020380 Actual loss orig 0.020380 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000970  Actual loss 0.079710 Actual loss orig 0.079710  \n",
      "error:  0.25553817 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020122  Actual loss 0.020122 Actual loss orig 0.020122 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.054499  Actual loss 0.079739 Actual loss orig 0.079739  \n",
      "error:  0.26091555 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079569  Actual loss 0.079569 Actual loss orig 0.079569 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.653910  Actual loss 0.003428 Actual loss orig 0.003428 \n",
      "error:  0.013386176 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071218  Actual loss 0.071218 Actual loss orig 0.071218 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.808821  Actual loss 0.007991 Actual loss orig 0.007991 \n",
      "error:  0.030906023 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061997  Actual loss 0.061997 Actual loss orig 0.061997 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.546723  Actual loss 0.011029 Actual loss orig 0.011029 \n",
      "error:  0.043475714 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053269  Actual loss 0.053269 Actual loss orig 0.053269 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.312361  Actual loss 0.014597 Actual loss orig 0.014597  \n",
      "error:  0.055277955 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022221  Actual loss 0.022221 Actual loss orig 0.022221 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.165867  Actual loss 0.049482 Actual loss orig 0.049482  \n",
      "error:  0.15967038 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020650  Actual loss 0.020650 Actual loss orig 0.020650 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.340662  Actual loss 0.060953 Actual loss orig 0.060953  \n",
      "error:  0.19076653 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079185  Actual loss 0.079185 Actual loss orig 0.079185 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.326198  Actual loss 0.002868 Actual loss orig 0.002868 \n",
      "error:  0.011143838 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071957  Actual loss 0.071957 Actual loss orig 0.071957 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.362539  Actual loss 0.004436 Actual loss orig 0.004436 \n",
      "error:  0.017187651 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061949  Actual loss 0.061949 Actual loss orig 0.061949 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.449252  Actual loss 0.007280 Actual loss orig 0.007280 \n",
      "error:  0.03180838 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051901  Actual loss 0.051901 Actual loss orig 0.051901 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.337928  Actual loss 0.008047 Actual loss orig 0.008047 \n",
      "error:  0.027600678 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025097  Actual loss 0.025097 Actual loss orig 0.025097 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.214547  Actual loss 0.014658 Actual loss orig 0.014658 \n",
      "error:  0.04597127 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017745  Actual loss 0.017745 Actual loss orig 0.017745 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.135671  Actual loss 0.018418 Actual loss orig 0.018418 \n",
      "error:  0.061654978 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079986  Actual loss 0.079986 Actual loss orig 0.079986 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.001103  Actual loss 0.007868 Actual loss orig 0.007868   \n",
      "error:  0.030742122 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069801  Actual loss 0.069801 Actual loss orig 0.069801 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000315  Actual loss 0.022703 Actual loss orig 0.022703   \n",
      "error:  0.08550883 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061843  Actual loss 0.061843 Actual loss orig 0.061843 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.027504  Actual loss 0.029282 Actual loss orig 0.029282   \n",
      "error:  0.107952155 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049330  Actual loss 0.049330 Actual loss orig 0.049330 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000006  Actual loss 0.046082 Actual loss orig 0.046082   \n",
      "error:  0.16426189 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023149  Actual loss 0.023149 Actual loss orig 0.023149 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000201  Actual loss 0.096284 Actual loss orig 0.096284   \n",
      "error:  0.31617373 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018004  Actual loss 0.018004 Actual loss orig 0.018004 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.008964  Actual loss 0.125880 Actual loss orig 0.125880    \n",
      "error:  0.39489004 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610ration 02990    Train loss 0.077799  Actual loss 0.077799 Actual loss orig 0.077799 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.005883  Actual loss 0.007080 Actual loss orig 0.007080   \n",
      "error:  0.027358957 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070795  Actual loss 0.070795 Actual loss orig 0.070795 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.019858  Actual loss 0.018533 Actual loss orig 0.018533   \n",
      "error:  0.06948044 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063907  Actual loss 0.063907 Actual loss orig 0.063907 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.002627  Actual loss 0.033756 Actual loss orig 0.033756   \n",
      "error:  0.1254339 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048111  Actual loss 0.048111 Actual loss orig 0.048111 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000014  Actual loss 0.052335 Actual loss orig 0.052335   \n",
      "error:  0.1838708 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.026133  Actual loss 0.026133 Actual loss orig 0.026133 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.005085  Actual loss 0.087916 Actual loss orig 0.087916   \n",
      "error:  0.28139344 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020601  Actual loss 0.020601 Actual loss orig 0.020601 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.103939  Actual loss 0.111766 Actual loss orig 0.111766   \n",
      "error:  0.35587344 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079094  Actual loss 0.079094 Actual loss orig 0.079094 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.206522  Actual loss 0.008135 Actual loss orig 0.008135  \n",
      "error:  0.031980623 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071819  Actual loss 0.071819 Actual loss orig 0.071819 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.015114  Actual loss 0.016619 Actual loss orig 0.016619  \n",
      "error:  0.061924446 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062687  Actual loss 0.062687 Actual loss orig 0.062687 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.024205  Actual loss 0.033221 Actual loss orig 0.033221   \n",
      "error:  0.12226384 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051207  Actual loss 0.051207 Actual loss orig 0.051207 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.004310  Actual loss 0.049356 Actual loss orig 0.049356   \n",
      "error:  0.17553778 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023835  Actual loss 0.023835 Actual loss orig 0.023835 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.092152 Actual loss orig 0.092152   \n",
      "error:  0.30151993 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020699  Actual loss 0.020699 Actual loss orig 0.020699 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000057  Actual loss 0.103345 Actual loss orig 0.103345   \n",
      "error:  0.32172334 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079500  Actual loss 0.079500 Actual loss orig 0.079500 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.205953  Actual loss 0.007545 Actual loss orig 0.007545  \n",
      "error:  0.029399758 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070275  Actual loss 0.070275 Actual loss orig 0.070275 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.200414  Actual loss 0.021317 Actual loss orig 0.021317  \n",
      "error:  0.08067219 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061911  Actual loss 0.061911 Actual loss orig 0.061911 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.001756  Actual loss 0.032233 Actual loss orig 0.032233  \n",
      "error:  0.11685968 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051955  Actual loss 0.051955 Actual loss orig 0.051955 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000598  Actual loss 0.045685 Actual loss orig 0.045685  \n",
      "error:  0.16206485 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024655  Actual loss 0.024655 Actual loss orig 0.024655 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.001105  Actual loss 0.095312 Actual loss orig 0.095312   \n",
      "error:  0.31423363 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019870  Actual loss 0.019870 Actual loss orig 0.019870 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.110830 Actual loss orig 0.110830   \n",
      "error:  0.34871382 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080317  Actual loss 0.080317 Actual loss orig 0.080317 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.309950  Actual loss 0.003935 Actual loss orig 0.003935 \n",
      "error:  0.015462871 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.072524  Actual loss 0.072524 Actual loss orig 0.072524 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.272570  Actual loss 0.014504 Actual loss orig 0.014504  \n",
      "error:  0.05564378 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062356  Actual loss 0.062356 Actual loss orig 0.062356 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.176998  Actual loss 0.029934 Actual loss orig 0.029934  \n",
      "error:  0.111263834 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050322  Actual loss 0.050322 Actual loss orig 0.050322 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.074411  Actual loss 0.041840 Actual loss orig 0.041840  \n",
      "error:  0.14906514 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025339  Actual loss 0.025339 Actual loss orig 0.025339 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000110  Actual loss 0.082286 Actual loss orig 0.082286  \n",
      "error:  0.2621461 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.014722  Actual loss 0.014722 Actual loss orig 0.014722 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000002  Actual loss 0.109677 Actual loss orig 0.109677  \n",
      "error:  0.3526029 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079075  Actual loss 0.079075 Actual loss orig 0.079075 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.038103  Actual loss 0.003543 Actual loss orig 0.003543 \n",
      "error:  0.013965062 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069898  Actual loss 0.069898 Actual loss orig 0.069898 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.938705  Actual loss 0.012235 Actual loss orig 0.012235 \n",
      "error:  0.045821864 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.059701  Actual loss 0.059701 Actual loss orig 0.059701 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.367999  Actual loss 0.022963 Actual loss orig 0.022963  \n",
      "error:  0.08623137 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052736  Actual loss 0.052736 Actual loss orig 0.052736 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.055597  Actual loss 0.023105 Actual loss orig 0.023105  \n",
      "error:  0.08390872 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025384  Actual loss 0.025384 Actual loss orig 0.025384 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000273  Actual loss 0.069063 Actual loss orig 0.069063  \n",
      "error:  0.22483738 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017840  Actual loss 0.017840 Actual loss orig 0.017840 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.002390  Actual loss 0.086863 Actual loss orig 0.086863  \n",
      "error:  0.28001574 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079153  Actual loss 0.079153 Actual loss orig 0.079153 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.501875  Actual loss 0.002647 Actual loss orig 0.002647 \n",
      "error:  0.01027064 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069968  Actual loss 0.069968 Actual loss orig 0.069968 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.885343  Actual loss 0.008424 Actual loss orig 0.008424 \n",
      "error:  0.03202598 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063298  Actual loss 0.063298 Actual loss orig 0.063298 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.588194  Actual loss 0.012083 Actual loss orig 0.012083 \n",
      "error:  0.044968307 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051062  Actual loss 0.051062 Actual loss orig 0.051062 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.511267  Actual loss 0.016504 Actual loss orig 0.016504  \n",
      "error:  0.05744945 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.020901  Actual loss 0.020901 Actual loss orig 0.020901 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.215694  Actual loss 0.050022 Actual loss orig 0.050022  \n",
      "error:  0.1609806 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018988  Actual loss 0.018988 Actual loss orig 0.018988 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.030942  Actual loss 0.052335 Actual loss orig 0.052335  \n",
      "error:  0.16515319 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079690  Actual loss 0.079690 Actual loss orig 0.079690 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.243866  Actual loss 0.002157 Actual loss orig 0.002157 \n",
      "error:  0.008582976 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070929  Actual loss 0.070929 Actual loss orig 0.070929 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.481565  Actual loss 0.005686 Actual loss orig 0.005686 \n",
      "error:  0.021212265 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062197  Actual loss 0.062197 Actual loss orig 0.062197 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830ation 09990    Train loss 0.437638  Actual loss 0.006869 Actual loss orig 0.006869 \n",
      "error:  0.024794139 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050760  Actual loss 0.050760 Actual loss orig 0.050760 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.325365  Actual loss 0.008006 Actual loss orig 0.008006 \n",
      "error:  0.027729554 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025562  Actual loss 0.025562 Actual loss orig 0.025562 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.255899  Actual loss 0.015699 Actual loss orig 0.015699 \n",
      "error:  0.050040033 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018125  Actual loss 0.018125 Actual loss orig 0.018125 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.587512  Actual loss 0.019182 Actual loss orig 0.019182 \n",
      "error:  0.05595466 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078130  Actual loss 0.078130 Actual loss orig 0.078130 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000822  Actual loss 0.006393 Actual loss orig 0.006393   \n",
      "error:  0.024888841 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070023  Actual loss 0.070023 Actual loss orig 0.070023 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000060  Actual loss 0.020127 Actual loss orig 0.020127   \n",
      "error:  0.07665992 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062445  Actual loss 0.062445 Actual loss orig 0.062445 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.017235  Actual loss 0.032318 Actual loss orig 0.032318   \n",
      "error:  0.12042496 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053010  Actual loss 0.053010 Actual loss orig 0.053010 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000293  Actual loss 0.047913 Actual loss orig 0.047913   \n",
      "error:  0.16737293 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025676  Actual loss 0.025676 Actual loss orig 0.025676 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000012  Actual loss 0.080611 Actual loss orig 0.080611   \n",
      "error:  0.26028994 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019143  Actual loss 0.019143 Actual loss orig 0.019143 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.128186 Actual loss orig 0.128186    \n",
      "error:  0.41430947 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078934  Actual loss 0.078934 Actual loss orig 0.078934 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.007911  Actual loss 0.007545 Actual loss orig 0.007545   \n",
      "error:  0.029799733 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070961  Actual loss 0.070961 Actual loss orig 0.070961 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.020087  Actual loss 0.018966 Actual loss orig 0.018966   \n",
      "error:  0.07209981 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062763  Actual loss 0.062763 Actual loss orig 0.062763 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.012653  Actual loss 0.036632 Actual loss orig 0.036632   \n",
      "error:  0.13604513 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.047426  Actual loss 0.047426 Actual loss orig 0.047426 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000000  Actual loss 0.053056 Actual loss orig 0.053056   \n",
      "error:  0.18446782 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024096  Actual loss 0.024096 Actual loss orig 0.024096 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.017438  Actual loss 0.093546 Actual loss orig 0.093546   \n",
      "error:  0.3056541 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016628  Actual loss 0.016628 Actual loss orig 0.016628 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.107158 Actual loss orig 0.107158   \n",
      "error:  0.34235165 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079320  Actual loss 0.079320 Actual loss orig 0.079320 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.480680  Actual loss 0.009683 Actual loss orig 0.009683  \n",
      "error:  0.03830119 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070058  Actual loss 0.070058 Actual loss orig 0.070058 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000004  Actual loss 0.020058 Actual loss orig 0.020058  \n",
      "error:  0.07644184 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061015  Actual loss 0.061015 Actual loss orig 0.061015 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.016639  Actual loss 0.032539 Actual loss orig 0.032539   \n",
      "error:  0.120908536 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050344  Actual loss 0.050344 Actual loss orig 0.050344 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000012  Actual loss 0.048103 Actual loss orig 0.048103   \n",
      "error:  0.17504787 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114150ion 02990    Train loss 0.025212  Actual loss 0.025212 Actual loss orig 0.025212 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.032288  Actual loss 0.093905 Actual loss orig 0.093905   \n",
      "error:  0.30848432 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020642  Actual loss 0.020642 Actual loss orig 0.020642 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.008113  Actual loss 0.096042 Actual loss orig 0.096042   \n",
      "error:  0.3114918 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078213  Actual loss 0.078213 Actual loss orig 0.078213 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.444088  Actual loss 0.008602 Actual loss orig 0.008602  \n",
      "error:  0.03354975 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070850  Actual loss 0.070850 Actual loss orig 0.070850 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.164594  Actual loss 0.020207 Actual loss orig 0.020207  \n",
      "error:  0.07676589 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062829  Actual loss 0.062829 Actual loss orig 0.062829 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000613  Actual loss 0.031264 Actual loss orig 0.031264  \n",
      "error:  0.11576237 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049149  Actual loss 0.049149 Actual loss orig 0.049149 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.062797  Actual loss 0.046746 Actual loss orig 0.046746  \n",
      "error:  0.16634244 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021963  Actual loss 0.021963 Actual loss orig 0.021963 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.009483  Actual loss 0.098268 Actual loss orig 0.098268   \n",
      "error:  0.31830814 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019680  Actual loss 0.019680 Actual loss orig 0.019680 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000003  Actual loss 0.098540 Actual loss orig 0.098540   \n",
      "error:  0.31298527 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.080057  Actual loss 0.080057 Actual loss orig 0.080057 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.205848  Actual loss 0.003368 Actual loss orig 0.003368 \n",
      "error:  0.013168574 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069834  Actual loss 0.069834 Actual loss orig 0.069834 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.364058  Actual loss 0.017268 Actual loss orig 0.017268  \n",
      "error:  0.066727474 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060040  Actual loss 0.060040 Actual loss orig 0.060040 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.053439  Actual loss 0.026140 Actual loss orig 0.026140  \n",
      "error:  0.09778973 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052856  Actual loss 0.052856 Actual loss orig 0.052856 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.024065  Actual loss 0.041923 Actual loss orig 0.041923  \n",
      "error:  0.1487038 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.027073  Actual loss 0.027073 Actual loss orig 0.027073 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000003  Actual loss 0.081650 Actual loss orig 0.081650  \n",
      "error:  0.2645349 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017858  Actual loss 0.017858 Actual loss orig 0.017858 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.099926 Actual loss orig 0.099926  \n",
      "error:  0.32599908 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078680  Actual loss 0.078680 Actual loss orig 0.078680 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.946745  Actual loss 0.003287 Actual loss orig 0.003287 \n",
      "error:  0.012835398 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070403  Actual loss 0.070403 Actual loss orig 0.070403 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.794349  Actual loss 0.010409 Actual loss orig 0.010409  \n",
      "error:  0.039653786 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061891  Actual loss 0.061891 Actual loss orig 0.061891 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.321825  Actual loss 0.019586 Actual loss orig 0.019586  \n",
      "error:  0.073642485 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052426  Actual loss 0.052426 Actual loss orig 0.052426 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.548310  Actual loss 0.027727 Actual loss orig 0.027727  \n",
      "error:  0.098555006 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022111  Actual loss 0.022111 Actual loss orig 0.022111 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.005740  Actual loss 0.068797 Actual loss orig 0.068797  \n",
      "error:  0.22301072 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018810  Actual loss 0.018810 Actual loss orig 0.018810 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.080559  Actual loss 0.085956 Actual loss orig 0.085956  \n",
      "error:  0.27375004 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079901  Actual loss 0.079901 Actual loss orig 0.079901 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.583157  Actual loss 0.002852 Actual loss orig 0.002852 \n",
      "error:  0.011334961 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071014  Actual loss 0.071014 Actual loss orig 0.071014 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.688792  Actual loss 0.006894 Actual loss orig 0.006894 \n",
      "error:  0.026493676 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061624  Actual loss 0.061624 Actual loss orig 0.061624 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.547948  Actual loss 0.010958 Actual loss orig 0.010958 \n",
      "error:  0.04226167 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050847  Actual loss 0.050847 Actual loss orig 0.050847 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.291774  Actual loss 0.015994 Actual loss orig 0.015994  \n",
      "error:  0.060003925 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021634  Actual loss 0.021634 Actual loss orig 0.021634 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.087737  Actual loss 0.049379 Actual loss orig 0.049379  \n",
      "error:  0.15545742 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.022665  Actual loss 0.022665 Actual loss orig 0.022665 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.014835  Actual loss 0.048579 Actual loss orig 0.048579  \n",
      "error:  0.15355703 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079336  Actual loss 0.079336 Actual loss orig 0.079336 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.322894  Actual loss 0.002861 Actual loss orig 0.002861 \n",
      "error:  0.011489494 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070172  Actual loss 0.070172 Actual loss orig 0.070172 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.532057  Actual loss 0.006326 Actual loss orig 0.006326 \n",
      "error:  0.023735516 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061253  Actual loss 0.061253 Actual loss orig 0.061253 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.421447  Actual loss 0.006982 Actual loss orig 0.006982 \n",
      "error:  0.0243495 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050008  Actual loss 0.050008 Actual loss orig 0.050008 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.311853  Actual loss 0.008282 Actual loss orig 0.008282 \n",
      "error:  0.030749796 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.027393  Actual loss 0.027393 Actual loss orig 0.027393 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.152414  Actual loss 0.014452 Actual loss orig 0.014452 \n",
      "error:  0.048052285 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019659  Actual loss 0.019659 Actual loss orig 0.019659 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.207204  Actual loss 0.016816 Actual loss orig 0.016816 \n",
      "error:  0.05084811 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079405  Actual loss 0.079405 Actual loss orig 0.079405 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000101  Actual loss 0.006866 Actual loss orig 0.006866   \n",
      "error:  0.026917728 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071680  Actual loss 0.071680 Actual loss orig 0.071680 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000008  Actual loss 0.019617 Actual loss orig 0.019617   \n",
      "error:  0.07519159 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063880  Actual loss 0.063880 Actual loss orig 0.063880 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000000  Actual loss 0.031570 Actual loss orig 0.031570   \n",
      "error:  0.11760395 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052719  Actual loss 0.052719 Actual loss orig 0.052719 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.111709  Actual loss 0.045856 Actual loss orig 0.045856   \n",
      "error:  0.16171953 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025156  Actual loss 0.025156 Actual loss orig 0.025156 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 1.676844  Actual loss 0.091742 Actual loss orig 0.091742  9 \n",
      "error:  0.30212265 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019503  Actual loss 0.019503 Actual loss orig 0.019503 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.002457  Actual loss 0.120090 Actual loss orig 0.120090   \n",
      "error:  0.38082513 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078943  Actual loss 0.078943 Actual loss orig 0.078943 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.086870  Actual loss 0.010273 Actual loss orig 0.010273  \n",
      "error:  0.040356584 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220ation 02990    Train loss 0.070682  Actual loss 0.070682 Actual loss orig 0.070682 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.020131 Actual loss orig 0.020131   \n",
      "error:  0.07672464 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063532  Actual loss 0.063532 Actual loss orig 0.063532 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.052685  Actual loss 0.031347 Actual loss orig 0.031347   \n",
      "error:  0.11623798 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052315  Actual loss 0.052315 Actual loss orig 0.052315 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.249020  Actual loss 0.048799 Actual loss orig 0.048799   \n",
      "error:  0.17375831 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022004  Actual loss 0.022004 Actual loss orig 0.022004 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000194  Actual loss 0.094830 Actual loss orig 0.094830   \n",
      "error:  0.30345097 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019002  Actual loss 0.019002 Actual loss orig 0.019002 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.121665 Actual loss orig 0.121665   \n",
      "error:  0.3853183 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078409  Actual loss 0.078409 Actual loss orig 0.078409 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.200630  Actual loss 0.010778 Actual loss orig 0.010778  \n",
      "error:  0.041652407 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069467  Actual loss 0.069467 Actual loss orig 0.069467 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.046116  Actual loss 0.019989 Actual loss orig 0.019989  \n",
      "error:  0.07538309 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060014  Actual loss 0.060014 Actual loss orig 0.060014 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.321883  Actual loss 0.040466 Actual loss orig 0.040466   \n",
      "error:  0.14835815 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053196  Actual loss 0.053196 Actual loss orig 0.053196 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000041  Actual loss 0.049611 Actual loss orig 0.049611   \n",
      "error:  0.17723443 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.026594  Actual loss 0.026594 Actual loss orig 0.026594 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000056  Actual loss 0.094891 Actual loss orig 0.094891   \n",
      "error:  0.30941734 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019020  Actual loss 0.019020 Actual loss orig 0.019020 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.003588  Actual loss 0.100495 Actual loss orig 0.100495   \n",
      "error:  0.32030207 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078632  Actual loss 0.078632 Actual loss orig 0.078632 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.018578  Actual loss 0.006972 Actual loss orig 0.006972  \n",
      "error:  0.027763704 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069953  Actual loss 0.069953 Actual loss orig 0.069953 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.042048  Actual loss 0.019452 Actual loss orig 0.019452  \n",
      "error:  0.07441128 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062259  Actual loss 0.062259 Actual loss orig 0.062259 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.001308  Actual loss 0.029472 Actual loss orig 0.029472  \n",
      "error:  0.108384185 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049401  Actual loss 0.049401 Actual loss orig 0.049401 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.011885  Actual loss 0.048036 Actual loss orig 0.048036  \n",
      "error:  0.16680238 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022243  Actual loss 0.022243 Actual loss orig 0.022243 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.093812 Actual loss orig 0.093812   \n",
      "error:  0.3016435 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018593  Actual loss 0.018593 Actual loss orig 0.018593 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000335  Actual loss 0.112288 Actual loss orig 0.112288   \n",
      "error:  0.35953403 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079627  Actual loss 0.079627 Actual loss orig 0.079627 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.865328  Actual loss 0.005266 Actual loss orig 0.005266  \n",
      "error:  0.020472284 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069881  Actual loss 0.069881 Actual loss orig 0.069881 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.366117  Actual loss 0.017695 Actual loss orig 0.017695  \n",
      "error:  0.06746173 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063177  Actual loss 0.063177 Actual loss orig 0.063177 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.080442  Actual loss 0.026417 Actual loss orig 0.026417  \n",
      "error:  0.099928975 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051662  Actual loss 0.051662 Actual loss orig 0.051662 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.453896  Actual loss 0.042680 Actual loss orig 0.042680  \n",
      "error:  0.1532837 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025662  Actual loss 0.025662 Actual loss orig 0.025662 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.001274  Actual loss 0.084273 Actual loss orig 0.084273  \n",
      "error:  0.2805333 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018345  Actual loss 0.018345 Actual loss orig 0.018345 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 4.451562  Actual loss 0.101971 Actual loss orig 0.101971  \n",
      "error:  0.31533456 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079793  Actual loss 0.079793 Actual loss orig 0.079793 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.065124  Actual loss 0.003672 Actual loss orig 0.003672 \n",
      "error:  0.014451648 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070145  Actual loss 0.070145 Actual loss orig 0.070145 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.866879  Actual loss 0.009676 Actual loss orig 0.009676  \n",
      "error:  0.03628801 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063569  Actual loss 0.063569 Actual loss orig 0.063569 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.252067  Actual loss 0.018310 Actual loss orig 0.018310  \n",
      "error:  0.06832354 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053098  Actual loss 0.053098 Actual loss orig 0.053098 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.088594  Actual loss 0.028477 Actual loss orig 0.028477  \n",
      "error:  0.10312126 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023527  Actual loss 0.023527 Actual loss orig 0.023527 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.690693  Actual loss 0.069653 Actual loss orig 0.069653  \n",
      "error:  0.23214246 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015350  Actual loss 0.015350 Actual loss orig 0.015350 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.004362  Actual loss 0.091333 Actual loss orig 0.091333  \n",
      "error:  0.28694135 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078363  Actual loss 0.078363 Actual loss orig 0.078363 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.616816  Actual loss 0.003398 Actual loss orig 0.003398 \n",
      "error:  0.0133150695 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071889  Actual loss 0.071889 Actual loss orig 0.071889 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.722776  Actual loss 0.006428 Actual loss orig 0.006428 \n",
      "error:  0.024810925 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063029  Actual loss 0.063029 Actual loss orig 0.063029 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.680970  Actual loss 0.011558 Actual loss orig 0.011558 \n",
      "error:  0.042395182 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048486  Actual loss 0.048486 Actual loss orig 0.048486 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.458603  Actual loss 0.018108 Actual loss orig 0.018108 \n",
      "error:  0.062045686 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023900  Actual loss 0.023900 Actual loss orig 0.023900 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.091783  Actual loss 0.049307 Actual loss orig 0.049307  \n",
      "error:  0.15937497 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017126  Actual loss 0.017126 Actual loss orig 0.017126 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.162114  Actual loss 0.058662 Actual loss orig 0.058662  \n",
      "error:  0.18466349 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078301  Actual loss 0.078301 Actual loss orig 0.078301 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.404994  Actual loss 0.003534 Actual loss orig 0.003534 \n",
      "error:  0.013971709 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070405  Actual loss 0.070405 Actual loss orig 0.070405 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.477023  Actual loss 0.005782 Actual loss orig 0.005782 \n",
      "error:  0.023027522 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064298  Actual loss 0.064298 Actual loss orig 0.064298 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.396174  Actual loss 0.006563 Actual loss orig 0.006563 \n",
      "error:  0.0258618 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051901  Actual loss 0.051901 Actual loss orig 0.051901 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 09990    Train loss 0.388927  Actual loss 0.010073 Actual loss orig 0.010073 \n",
      "error:  0.03897212 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022213  Actual loss 0.022213 Actual loss orig 0.022213 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.244004  Actual loss 0.017345 Actual loss orig 0.017345 \n",
      "error:  0.054897193 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.024447  Actual loss 0.024447 Actual loss orig 0.024447 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.082008  Actual loss 0.014964 Actual loss orig 0.014964 \n",
      "error:  0.04814739 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079307  Actual loss 0.079307 Actual loss orig 0.079307 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000000  Actual loss 0.007018 Actual loss orig 0.007018   \n",
      "error:  0.02726801 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070205  Actual loss 0.070205 Actual loss orig 0.070205 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.022261 Actual loss orig 0.022261   \n",
      "error:  0.08553282 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062029  Actual loss 0.062029 Actual loss orig 0.062029 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000663  Actual loss 0.026144 Actual loss orig 0.026144   \n",
      "error:  0.0953617 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051720  Actual loss 0.051720 Actual loss orig 0.051720 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.002698  Actual loss 0.045724 Actual loss orig 0.045724   \n",
      "error:  0.16356286 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022571  Actual loss 0.022571 Actual loss orig 0.022571 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.006573  Actual loss 0.096133 Actual loss orig 0.096133   \n",
      "error:  0.31721085 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020396  Actual loss 0.020396 Actual loss orig 0.020396 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.297495  Actual loss 0.121554 Actual loss orig 0.121554    \n",
      "error:  0.38585722 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.077870  Actual loss 0.077870 Actual loss orig 0.077870 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.031610  Actual loss 0.011061 Actual loss orig 0.011061  \n",
      "error:  0.04390891 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070510  Actual loss 0.070510 Actual loss orig 0.070510 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000855  Actual loss 0.021264 Actual loss orig 0.021264  \n",
      "error:  0.08039674 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063321  Actual loss 0.063321 Actual loss orig 0.063321 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000000  Actual loss 0.035542 Actual loss orig 0.035542   \n",
      "error:  0.13050964 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052506  Actual loss 0.052506 Actual loss orig 0.052506 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.003588  Actual loss 0.054683 Actual loss orig 0.054683   \n",
      "error:  0.19695175 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.026063  Actual loss 0.026063 Actual loss orig 0.026063 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.087674 Actual loss orig 0.087674   \n",
      "error:  0.28294218 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.021878  Actual loss 0.021878 Actual loss orig 0.021878 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000018  Actual loss 0.100033 Actual loss orig 0.100033   \n",
      "error:  0.3159305 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079876  Actual loss 0.079876 Actual loss orig 0.079876 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.196199  Actual loss 0.009134 Actual loss orig 0.009134  \n",
      "error:  0.03605544 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069934  Actual loss 0.069934 Actual loss orig 0.069934 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.003185  Actual loss 0.019692 Actual loss orig 0.019692   \n",
      "error:  0.07388464 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.059688  Actual loss 0.059688 Actual loss orig 0.059688 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000011  Actual loss 0.035803 Actual loss orig 0.035803   \n",
      "error:  0.1296341 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048676  Actual loss 0.048676 Actual loss orig 0.048676 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.012701  Actual loss 0.056436 Actual loss orig 0.056436   \n",
      "error:  0.20000161 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.027143  Actual loss 0.027143 Actual loss orig 0.027143 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.002532  Actual loss 0.092576 Actual loss orig 0.092576   \n",
      "error:  0.30077812 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315250ion 02990    Train loss 0.017106  Actual loss 0.017106 Actual loss orig 0.017106 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.108962 Actual loss orig 0.108962   \n",
      "error:  0.34796438 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078669  Actual loss 0.078669 Actual loss orig 0.078669 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.031596  Actual loss 0.007692 Actual loss orig 0.007692  \n",
      "error:  0.030071964 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070420  Actual loss 0.070420 Actual loss orig 0.070420 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.002163  Actual loss 0.022243 Actual loss orig 0.022243  \n",
      "error:  0.08650031 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062961  Actual loss 0.062961 Actual loss orig 0.062961 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.001083  Actual loss 0.034407 Actual loss orig 0.034407  \n",
      "error:  0.12581246 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049648  Actual loss 0.049648 Actual loss orig 0.049648 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.000000  Actual loss 0.046329 Actual loss orig 0.046329  \n",
      "error:  0.16408455 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023301  Actual loss 0.023301 Actual loss orig 0.023301 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000001  Actual loss 0.093578 Actual loss orig 0.093578   \n",
      "error:  0.3038682 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020856  Actual loss 0.020856 Actual loss orig 0.020856 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000160  Actual loss 0.111488 Actual loss orig 0.111488   \n",
      "error:  0.34943977 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079533  Actual loss 0.079533 Actual loss orig 0.079533 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.423313  Actual loss 0.004355 Actual loss orig 0.004355  \n",
      "error:  0.017193139 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070725  Actual loss 0.070725 Actual loss orig 0.070725 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.324570  Actual loss 0.020680 Actual loss orig 0.020680  \n",
      "error:  0.07942525 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064477  Actual loss 0.064477 Actual loss orig 0.064477 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.018626  Actual loss 0.022645 Actual loss orig 0.022645  \n",
      "error:  0.086644836 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050037  Actual loss 0.050037 Actual loss orig 0.050037 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.440495  Actual loss 0.037081 Actual loss orig 0.037081  \n",
      "error:  0.13252531 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021662  Actual loss 0.021662 Actual loss orig 0.021662 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000721  Actual loss 0.095585 Actual loss orig 0.095585  \n",
      "error:  0.30128747 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017558  Actual loss 0.017558 Actual loss orig 0.017558 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.103765 Actual loss orig 0.103765  \n",
      "error:  0.32847288 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078648  Actual loss 0.078648 Actual loss orig 0.078648 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.299649  Actual loss 0.004084 Actual loss orig 0.004084  \n",
      "error:  0.015940888 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070169  Actual loss 0.070169 Actual loss orig 0.070169 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.781787  Actual loss 0.012824 Actual loss orig 0.012824  \n",
      "error:  0.048564345 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062465  Actual loss 0.062465 Actual loss orig 0.062465 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.325371  Actual loss 0.016276 Actual loss orig 0.016276  \n",
      "error:  0.059553813 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051312  Actual loss 0.051312 Actual loss orig 0.051312 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.204052  Actual loss 0.025641 Actual loss orig 0.025641  \n",
      "error:  0.09110186 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024508  Actual loss 0.024508 Actual loss orig 0.024508 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000124  Actual loss 0.069792 Actual loss orig 0.069792  \n",
      "error:  0.23017903 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016405  Actual loss 0.016405 Actual loss orig 0.016405 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.008245  Actual loss 0.093950 Actual loss orig 0.093950  \n",
      "error:  0.2982476 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079402  Actual loss 0.079402 Actual loss orig 0.079402 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.581979  Actual loss 0.002983 Actual loss orig 0.002983 \n",
      "error:  0.011542422 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071943  Actual loss 0.071943 Actual loss orig 0.071943 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.702625  Actual loss 0.006195 Actual loss orig 0.006195 \n",
      "error:  0.023065675 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061212  Actual loss 0.061212 Actual loss orig 0.061212 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.530511  Actual loss 0.010801 Actual loss orig 0.010801 \n",
      "error:  0.039484315 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050915  Actual loss 0.050915 Actual loss orig 0.050915 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.435267  Actual loss 0.015629 Actual loss orig 0.015629  \n",
      "error:  0.053621586 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023821  Actual loss 0.023821 Actual loss orig 0.023821 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.169947  Actual loss 0.046146 Actual loss orig 0.046146  \n",
      "error:  0.14549191 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016522  Actual loss 0.016522 Actual loss orig 0.016522 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.040677  Actual loss 0.059661 Actual loss orig 0.059661  \n",
      "error:  0.19153115 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079462  Actual loss 0.079462 Actual loss orig 0.079462 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.370880  Actual loss 0.003216 Actual loss orig 0.003216 \n",
      "error:  0.0124611575 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070919  Actual loss 0.070919 Actual loss orig 0.070919 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.360628  Actual loss 0.004312 Actual loss orig 0.004312 \n",
      "error:  0.016377378 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063996  Actual loss 0.063996 Actual loss orig 0.063996 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.440832  Actual loss 0.006757 Actual loss orig 0.006757 \n",
      "error:  0.024257837 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049703  Actual loss 0.049703 Actual loss orig 0.049703 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.437092  Actual loss 0.009131 Actual loss orig 0.009131 \n",
      "error:  0.031578463 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024488  Actual loss 0.024488 Actual loss orig 0.024488 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.280493  Actual loss 0.015466 Actual loss orig 0.015466 \n",
      "error:  0.052984312 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015926  Actual loss 0.015926 Actual loss orig 0.015926 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.168810  Actual loss 0.020234 Actual loss orig 0.020234 \n",
      "error:  0.06508237 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079424  Actual loss 0.079424 Actual loss orig 0.079424 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000000  Actual loss 0.006377 Actual loss orig 0.006377   \n",
      "error:  0.025235727 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070450  Actual loss 0.070450 Actual loss orig 0.070450 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000049  Actual loss 0.017843 Actual loss orig 0.017843   \n",
      "error:  0.067821756 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.064634  Actual loss 0.064634 Actual loss orig 0.064634 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000182  Actual loss 0.029565 Actual loss orig 0.029565   \n",
      "error:  0.110917054 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049836  Actual loss 0.049836 Actual loss orig 0.049836 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.014819  Actual loss 0.052774 Actual loss orig 0.052774   \n",
      "error:  0.183914 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023063  Actual loss 0.023063 Actual loss orig 0.023063 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.076796  Actual loss 0.089062 Actual loss orig 0.089062   \n",
      "error:  0.2905352 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019225  Actual loss 0.019225 Actual loss orig 0.019225 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000100  Actual loss 0.102773 Actual loss orig 0.102773   \n",
      "error:  0.33146235 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.077397  Actual loss 0.077397 Actual loss orig 0.077397 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.044364  Actual loss 0.007602 Actual loss orig 0.007602  \n",
      "error:  0.029510438 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069806  Actual loss 0.069806 Actual loss orig 0.069806 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000124  Actual loss 0.020803 Actual loss orig 0.020803   \n",
      "error:  0.07898686 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830ation 02990    Train loss 0.062300  Actual loss 0.062300 Actual loss orig 0.062300 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.163808  Actual loss 0.033543 Actual loss orig 0.033543   \n",
      "error:  0.122680835 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051500  Actual loss 0.051500 Actual loss orig 0.051500 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.009126  Actual loss 0.049203 Actual loss orig 0.049203   \n",
      "error:  0.17255485 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022980  Actual loss 0.022980 Actual loss orig 0.022980 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000676  Actual loss 0.093280 Actual loss orig 0.093280   \n",
      "error:  0.30303308 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015525  Actual loss 0.015525 Actual loss orig 0.015525 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000005  Actual loss 0.123311 Actual loss orig 0.123311   \n",
      "error:  0.38187298 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079060  Actual loss 0.079060 Actual loss orig 0.079060 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.257725  Actual loss 0.011236 Actual loss orig 0.011236  \n",
      "error:  0.04470153 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071095  Actual loss 0.071095 Actual loss orig 0.071095 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.019484 Actual loss orig 0.019484  \n",
      "error:  0.07463896 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061702  Actual loss 0.061702 Actual loss orig 0.061702 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000109  Actual loss 0.032326 Actual loss orig 0.032326  \n",
      "error:  0.119991645 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050389  Actual loss 0.050389 Actual loss orig 0.050389 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.003815  Actual loss 0.047141 Actual loss orig 0.047141   \n",
      "error:  0.16726156 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022007  Actual loss 0.022007 Actual loss orig 0.022007 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000059  Actual loss 0.090433 Actual loss orig 0.090433   \n",
      "error:  0.29276916 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017928  Actual loss 0.017928 Actual loss orig 0.017928 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000421  Actual loss 0.112477 Actual loss orig 0.112477   \n",
      "error:  0.3577014 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079174  Actual loss 0.079174 Actual loss orig 0.079174 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.157529  Actual loss 0.005168 Actual loss orig 0.005168  \n",
      "error:  0.020803362 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070423  Actual loss 0.070423 Actual loss orig 0.070423 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.011526  Actual loss 0.022123 Actual loss orig 0.022123  \n",
      "error:  0.08394078 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060981  Actual loss 0.060981 Actual loss orig 0.060981 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.009320  Actual loss 0.032936 Actual loss orig 0.032936  \n",
      "error:  0.12019926 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048033  Actual loss 0.048033 Actual loss orig 0.048033 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.050756  Actual loss 0.048312 Actual loss orig 0.048312  \n",
      "error:  0.16944371 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.023707  Actual loss 0.023707 Actual loss orig 0.023707 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.088614 Actual loss orig 0.088614   \n",
      "error:  0.2858892 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.014244  Actual loss 0.014244 Actual loss orig 0.014244 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.309627  Actual loss 0.106448 Actual loss orig 0.106448   \n",
      "error:  0.33714995 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079285  Actual loss 0.079285 Actual loss orig 0.079285 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.228746  Actual loss 0.004124 Actual loss orig 0.004124 \n",
      "error:  0.016341753 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.069635  Actual loss 0.069635 Actual loss orig 0.069635 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.312906  Actual loss 0.018619 Actual loss orig 0.018619  \n",
      "error:  0.07087974 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063065  Actual loss 0.063065 Actual loss orig 0.063065 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.041264  Actual loss 0.024175 Actual loss orig 0.024175  \n",
      "error:  0.09039293 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048486  Actual loss 0.048486 Actual loss orig 0.048486 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.034506  Actual loss 0.044867 Actual loss orig 0.044867  \n",
      "error:  0.16056749 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025426  Actual loss 0.025426 Actual loss orig 0.025426 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000001  Actual loss 0.091066 Actual loss orig 0.091066  \n",
      "error:  0.29682946 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017633  Actual loss 0.017633 Actual loss orig 0.017633 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.024563  Actual loss 0.101953 Actual loss orig 0.101953  \n",
      "error:  0.32987043 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079317  Actual loss 0.079317 Actual loss orig 0.079317 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.099436  Actual loss 0.003397 Actual loss orig 0.003397 \n",
      "error:  0.013192903 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071560  Actual loss 0.071560 Actual loss orig 0.071560 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.709912  Actual loss 0.011211 Actual loss orig 0.011211 \n",
      "error:  0.041648027 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060785  Actual loss 0.060785 Actual loss orig 0.060785 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.400081  Actual loss 0.019608 Actual loss orig 0.019608  \n",
      "error:  0.07230066 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.053830  Actual loss 0.053830 Actual loss orig 0.053830 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.235690  Actual loss 0.029464 Actual loss orig 0.029464  \n",
      "error:  0.10667459 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025004  Actual loss 0.025004 Actual loss orig 0.025004 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.025265  Actual loss 0.075984 Actual loss orig 0.075984  \n",
      "error:  0.249668 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015314  Actual loss 0.015314 Actual loss orig 0.015314 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.039492  Actual loss 0.093645 Actual loss orig 0.093645  \n",
      "error:  0.28952703 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078877  Actual loss 0.078877 Actual loss orig 0.078877 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.630882  Actual loss 0.003323 Actual loss orig 0.003323  \n",
      "error:  0.01308885 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071682  Actual loss 0.071682 Actual loss orig 0.071682 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.595558  Actual loss 0.005887 Actual loss orig 0.005887 \n",
      "error:  0.023277974 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062513  Actual loss 0.062513 Actual loss orig 0.062513 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.488927  Actual loss 0.010761 Actual loss orig 0.010761 \n",
      "error:  0.039906804 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050270  Actual loss 0.050270 Actual loss orig 0.050270 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.448494  Actual loss 0.018469 Actual loss orig 0.018469  \n",
      "error:  0.06301147 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024050  Actual loss 0.024050 Actual loss orig 0.024050 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.202462  Actual loss 0.041381 Actual loss orig 0.041381  \n",
      "error:  0.13205776 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019529  Actual loss 0.019529 Actual loss orig 0.019529 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.062031  Actual loss 0.055938 Actual loss orig 0.055938  \n",
      "error:  0.17916223 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078268  Actual loss 0.078268 Actual loss orig 0.078268 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.282871  Actual loss 0.002431 Actual loss orig 0.002431 \n",
      "error:  0.009404181 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071409  Actual loss 0.071409 Actual loss orig 0.071409 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.332612  Actual loss 0.004146 Actual loss orig 0.004146 \n",
      "error:  0.015845299 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.063240  Actual loss 0.063240 Actual loss orig 0.063240 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.440749  Actual loss 0.007098 Actual loss orig 0.007098 \n",
      "error:  0.027041683 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050085  Actual loss 0.050085 Actual loss orig 0.050085 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.304805  Actual loss 0.008030 Actual loss orig 0.008030 \n",
      "error:  0.027658056 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.021779  Actual loss 0.021779 Actual loss orig 0.021779 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114150ion 09990    Train loss 0.333138  Actual loss 0.017095 Actual loss orig 0.017095 \n",
      "error:  0.05618477 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019549  Actual loss 0.019549 Actual loss orig 0.019549 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.219775  Actual loss 0.016901 Actual loss orig 0.016901 \n",
      "error:  0.05327809 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079548  Actual loss 0.079548 Actual loss orig 0.079548 \n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.000007  Actual loss 0.007608 Actual loss orig 0.007608   \n",
      "error:  0.02995856 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071158  Actual loss 0.071158 Actual loss orig 0.071158 \n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.008541  Actual loss 0.021063 Actual loss orig 0.021063   \n",
      "error:  0.08121605 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.060590  Actual loss 0.060590 Actual loss orig 0.060590 \n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000903  Actual loss 0.045133 Actual loss orig 0.045133   \n",
      "error:  0.1668963 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051815  Actual loss 0.051815 Actual loss orig 0.051815 \n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.103129  Actual loss 0.050334 Actual loss orig 0.050334   \n",
      "error:  0.18370834 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025365  Actual loss 0.025365 Actual loss orig 0.025365 \n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000050  Actual loss 0.100882 Actual loss orig 0.100882   \n",
      "error:  0.3283541 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.020196  Actual loss 0.020196 Actual loss orig 0.020196 \n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000302  Actual loss 0.118696 Actual loss orig 0.118696   \n",
      "error:  0.37614408 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078914  Actual loss 0.078914 Actual loss orig 0.078914 \n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.001327  Actual loss 0.007027 Actual loss orig 0.007027   \n",
      "error:  0.027997505 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071321  Actual loss 0.071321 Actual loss orig 0.071321 \n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.000000  Actual loss 0.019340 Actual loss orig 0.019340   \n",
      "error:  0.07253185 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062835  Actual loss 0.062835 Actual loss orig 0.062835 \n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000000  Actual loss 0.033625 Actual loss orig 0.033625   \n",
      "error:  0.1250434 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052031  Actual loss 0.052031 Actual loss orig 0.052031 \n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.007577  Actual loss 0.048634 Actual loss orig 0.048634   \n",
      "error:  0.17263107 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.022726  Actual loss 0.022726 Actual loss orig 0.022726 \n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.008678  Actual loss 0.094960 Actual loss orig 0.094960   \n",
      "error:  0.3060353 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015822  Actual loss 0.015822 Actual loss orig 0.015822 \n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.121593 Actual loss orig 0.121593   \n",
      "error:  0.38102746 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078133  Actual loss 0.078133 Actual loss orig 0.078133 \n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.315811  Actual loss 0.010119 Actual loss orig 0.010119  \n",
      "error:  0.04000211 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071196  Actual loss 0.071196 Actual loss orig 0.071196 \n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.027756  Actual loss 0.017915 Actual loss orig 0.017915  \n",
      "error:  0.06721787 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062910  Actual loss 0.062910 Actual loss orig 0.062910 \n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000231  Actual loss 0.033780 Actual loss orig 0.033780   \n",
      "error:  0.12637825 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050399  Actual loss 0.050399 Actual loss orig 0.050399 \n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.012568  Actual loss 0.054690 Actual loss orig 0.054690   \n",
      "error:  0.19240233 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025575  Actual loss 0.025575 Actual loss orig 0.025575 \n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000001  Actual loss 0.092362 Actual loss orig 0.092362   \n",
      "error:  0.30761525 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.015445  Actual loss 0.015445 Actual loss orig 0.015445 \n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.114567 Actual loss orig 0.114567   \n",
      "error:  0.36583143 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610ration 02990    Train loss 0.079193  Actual loss 0.079193 Actual loss orig 0.079193 \n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 2.233122  Actual loss 0.008117 Actual loss orig 0.008117  \n",
      "error:  0.032365028 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070216  Actual loss 0.070216 Actual loss orig 0.070216 \n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.527279  Actual loss 0.024459 Actual loss orig 0.024459  \n",
      "error:  0.09265701 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062635  Actual loss 0.062635 Actual loss orig 0.062635 \n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.000222  Actual loss 0.034089 Actual loss orig 0.034089  \n",
      "error:  0.12584935 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.052550  Actual loss 0.052550 Actual loss orig 0.052550 \n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.219577  Actual loss 0.044890 Actual loss orig 0.044890  \n",
      "error:  0.1596153 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025004  Actual loss 0.025004 Actual loss orig 0.025004 \n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.000000  Actual loss 0.093557 Actual loss orig 0.093557   \n",
      "error:  0.30253845 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.016782  Actual loss 0.016782 Actual loss orig 0.016782 \n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000000  Actual loss 0.099170 Actual loss orig 0.099170   \n",
      "error:  0.31910968 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078949  Actual loss 0.078949 Actual loss orig 0.078949 \n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 1.425970  Actual loss 0.004480 Actual loss orig 0.004480 \n",
      "error:  0.017754497 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.072020  Actual loss 0.072020 Actual loss orig 0.072020 \n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.228907  Actual loss 0.016068 Actual loss orig 0.016068  \n",
      "error:  0.06062396 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061464  Actual loss 0.061464 Actual loss orig 0.061464 \n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.194553  Actual loss 0.025715 Actual loss orig 0.025715  \n",
      "error:  0.09495589 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.050940  Actual loss 0.050940 Actual loss orig 0.050940 \n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.019401  Actual loss 0.037680 Actual loss orig 0.037680  \n",
      "error:  0.13671796 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.027952  Actual loss 0.027952 Actual loss orig 0.027952 \n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.077476  Actual loss 0.077334 Actual loss orig 0.077334  \n",
      "error:  0.25376543 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.014488  Actual loss 0.014488 Actual loss orig 0.014488 \n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000001  Actual loss 0.106585 Actual loss orig 0.106585  \n",
      "error:  0.33570814 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079444  Actual loss 0.079444 Actual loss orig 0.079444 \n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.886130  Actual loss 0.003212 Actual loss orig 0.003212  \n",
      "error:  0.012535307 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070043  Actual loss 0.070043 Actual loss orig 0.070043 \n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.908968  Actual loss 0.012054 Actual loss orig 0.012054  \n",
      "error:  0.044825863 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062495  Actual loss 0.062495 Actual loss orig 0.062495 \n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.456087  Actual loss 0.021378 Actual loss orig 0.021378  \n",
      "error:  0.0821601 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.051936  Actual loss 0.051936 Actual loss orig 0.051936 \n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.251059  Actual loss 0.025937 Actual loss orig 0.025937  \n",
      "error:  0.09417079 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.028675  Actual loss 0.028675 Actual loss orig 0.028675 \n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.002527  Actual loss 0.070330 Actual loss orig 0.070330  \n",
      "error:  0.23199818 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.018258  Actual loss 0.018258 Actual loss orig 0.018258 \n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.000325  Actual loss 0.089417 Actual loss orig 0.089417  \n",
      "error:  0.2857466 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.078824  Actual loss 0.078824 Actual loss orig 0.078824 \n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.566764  Actual loss 0.002907 Actual loss orig 0.002907 \n",
      "error:  0.011494391 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.071475  Actual loss 0.071475 Actual loss orig 0.071475 \n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.762382  Actual loss 0.007005 Actual loss orig 0.007005 \n",
      "error:  0.026185624 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.061951  Actual loss 0.061951 Actual loss orig 0.061951 \n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.564859  Actual loss 0.010291 Actual loss orig 0.010291 \n",
      "error:  0.039112985 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.049900  Actual loss 0.049900 Actual loss orig 0.049900 \n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.566287  Actual loss 0.017180 Actual loss orig 0.017180  \n",
      "error:  0.060170792 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.024492  Actual loss 0.024492 Actual loss orig 0.024492 \n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.112054  Actual loss 0.041880 Actual loss orig 0.041880  \n",
      "error:  0.13551003 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.019852  Actual loss 0.019852 Actual loss orig 0.019852 \n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.014848  Actual loss 0.052882 Actual loss orig 0.052882  \n",
      "error:  0.17073895 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 02990    Train loss 0.079243  Actual loss 0.079243 Actual loss orig 0.079243 \n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 09990    Train loss 0.281537  Actual loss 0.002505 Actual loss orig 0.002505 \n",
      "error:  0.010031846 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 02990    Train loss 0.070209  Actual loss 0.070209 Actual loss orig 0.070209 \n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 09990    Train loss 0.512154  Actual loss 0.006292 Actual loss orig 0.006292 \n",
      "error:  0.024836415 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 02990    Train loss 0.062677  Actual loss 0.062677 Actual loss orig 0.062677 \n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 09990    Train loss 0.375840  Actual loss 0.006285 Actual loss orig 0.006285 \n",
      "error:  0.024497345 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 02990    Train loss 0.048674  Actual loss 0.048674 Actual loss orig 0.048674 \n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 09990    Train loss 0.493047  Actual loss 0.010226 Actual loss orig 0.010226 \n",
      "error:  0.03444927 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 02990    Train loss 0.025422  Actual loss 0.025422 Actual loss orig 0.025422 \n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 09990    Train loss 0.155277  Actual loss 0.012873 Actual loss orig 0.012873 \n",
      "error:  0.040065497 \n",
      "\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 02990    Train loss 0.017931  Actual loss 0.017931 Actual loss orig 0.017931 \n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 09990    Train loss 0.168494  Actual loss 0.016201 Actual loss orig 0.016201 \n",
      "error:  0.051581405 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "numpoints = 8\n",
    "ms = [ int(100*np.exp(5.5/numpoints*i)) for i in range(numpoints) ] #[100,200,,17000]\n",
    "print(ms)\n",
    "ks = [10,20,30,50,150,250]\n",
    "err = np.zeros((len(ms), len(ks)))\n",
    "\n",
    "numit = 10\n",
    "\n",
    "for q in range(numit):\n",
    "    for j,m in enumerate(ms):\n",
    "        for ell,k in enumerate(ks):\n",
    "            # generate input\n",
    "            num_channels = [k]*4\n",
    "            ni = get_net_input(num_channels)\n",
    "        \n",
    "            # get random noise, and find approximation to it in the range of the generator\n",
    "            img_var.data.uniform_()\n",
    "            img_approx = Variable(dd_recovery(img_var,img_var,num_channels,ni=ni,apply_f=None,num_iter=3000))\n",
    "\n",
    "            print(\"number useful variables / number observations\", (k**2*4 + k) /m)\n",
    "            print(\"number observations / number of variables\", m/n)\n",
    "            print(\"m,n,nump\",m,n,k**2*4 + k)\n",
    "            \n",
    "            # generate random matrix\n",
    "            A = 10*torch.empty(n,m).normal_(0, 1/np.sqrt(m)).type(dtype)\n",
    "            \n",
    "            def forwardm(img):\n",
    "                X = img.view(-1 , np.prod(img.shape) )\n",
    "                return torch.mm(X,A)\n",
    "\n",
    "            measurement = forwardm(img_approx).type(dtype)\n",
    "            out_img_var = dd_recovery(measurement,img_approx,num_channels,ni=ni,apply_f=forwardm,num_iter=10000)\n",
    "    \n",
    "            #plot_img(img_approx.data.cpu().numpy()[0,0])\n",
    "            #plot_img(out_img_var.data.cpu().numpy()[0,0])\n",
    "    \n",
    "            error = snr(out_img_var.data.cpu().numpy()[0] , img_approx.data.cpu().numpy()[0])\n",
    "            print(\"error: \", error, \"\\n\")\n",
    "            err[j,ell] += error/numit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save\n",
    "plt.xscale('log')\n",
    "for i,c in enumerate(['b','r','g','y','b']):\n",
    "    plt.plot(ms,err[:,i],c)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"csrandimg_\"+img_name+\".csv\", np.vstack([ np.array(ms) ,np.array(err).T]).T , delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressive sensing on a natural image for varying number of parameters and number of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000115  Actual loss 0.084647 Actual loss orig 0.084647    \n",
      "error:  0.99586666 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.044837 Actual loss orig 0.044837    \n",
      "error:  0.52752805 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.039256 Actual loss orig 0.039256    \n",
      "error:  0.46186325 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000857  Actual loss 0.038368 Actual loss orig 0.038368    \n",
      "error:  0.45143074 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.068989  Actual loss 0.040185 Actual loss orig 0.040185  6 \n",
      "error:  0.47190532 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000543  Actual loss 0.045252 Actual loss orig 0.045252    \n",
      "error:  0.5323641 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.028095  Actual loss 0.053413 Actual loss orig 0.053413    \n",
      "error:  0.62984765 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.030129 Actual loss orig 0.030129    \n",
      "error:  0.35447565 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 1.084534  Actual loss 0.022729 Actual loss orig 0.022729    \n",
      "error:  0.26276717 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.005029  Actual loss 0.021689 Actual loss orig 0.021689    \n",
      "error:  0.25565335 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.025324 Actual loss orig 0.025324    \n",
      "error:  0.29794884 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.001280  Actual loss 0.017645 Actual loss orig 0.017645    \n",
      "error:  0.20770729 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.407086  Actual loss 0.047647 Actual loss orig 0.047647   \n",
      "error:  0.55359286 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.220385  Actual loss 0.015189 Actual loss orig 0.015189   \n",
      "error:  0.18035693 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000213  Actual loss 0.013504 Actual loss orig 0.013504   \n",
      "error:  0.15885839 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.007016  Actual loss 0.009736 Actual loss orig 0.009736   \n",
      "error:  0.1146507 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001725  Actual loss 0.011020 Actual loss orig 0.011020   \n",
      "error:  0.12993442 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.009101 Actual loss orig 0.009101   \n",
      "error:  0.10707055 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 6.392492  Actual loss 0.022457 Actual loss orig 0.022457   \n",
      "error:  0.26662332 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.031561  Actual loss 0.007822 Actual loss orig 0.007822   \n",
      "error:  0.09239866 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.018017  Actual loss 0.004779 Actual loss orig 0.004779   \n",
      "error:  0.0561288 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000603  Actual loss 0.004238 Actual loss orig 0.004238   \n",
      "error:  0.049853403 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000013  Actual loss 0.003798 Actual loss orig 0.003798   \n",
      "error:  0.04468519 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.082627  Actual loss 0.002673 Actual loss orig 0.002673   \n",
      "error:  0.03143063 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.937585  Actual loss 0.005373 Actual loss orig 0.005373   \n",
      "error:  0.06451001 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.130391  Actual loss 0.001809 Actual loss orig 0.001809   \n",
      "error:  0.021478705 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.158434  Actual loss 0.001951 Actual loss orig 0.001951   \n",
      "error:  0.022656828 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 05990    Train loss 0.011215  Actual loss 0.001326 Actual loss orig 0.001326   \n",
      "error:  0.015611717 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000184  Actual loss 0.001153 Actual loss orig 0.001153   \n",
      "error:  0.013616824 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.098616  Actual loss 0.000681 Actual loss orig 0.000681   \n",
      "error:  0.0076629524 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.407205  Actual loss 0.004227 Actual loss orig 0.004227  \n",
      "error:  0.048906974 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.205877  Actual loss 0.001055 Actual loss orig 0.001055  \n",
      "error:  0.011730883 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.081948  Actual loss 0.000779 Actual loss orig 0.000779  \n",
      "error:  0.008679334 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.039149  Actual loss 0.000653 Actual loss orig 0.000653  \n",
      "error:  0.008256434 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.009664  Actual loss 0.000350 Actual loss orig 0.000350  \n",
      "error:  0.0042290217 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.005779  Actual loss 0.000369 Actual loss orig 0.000369  \n",
      "error:  0.004304894 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.737576  Actual loss 0.003606 Actual loss orig 0.003606  \n",
      "error:  0.04230484 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.154696  Actual loss 0.001082 Actual loss orig 0.001082  \n",
      "error:  0.012778692 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.031601  Actual loss 0.000312 Actual loss orig 0.000312  \n",
      "error:  0.0046142857 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.038945  Actual loss 0.000340 Actual loss orig 0.000340  \n",
      "error:  0.0031715857 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.016653  Actual loss 0.000204 Actual loss orig 0.000204  \n",
      "error:  0.002722429 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.005409  Actual loss 0.000188 Actual loss orig 0.000188  \n",
      "error:  0.0032610272 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.240468  Actual loss 0.002017 Actual loss orig 0.002017  \n",
      "error:  0.02410738 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.040159  Actual loss 0.000408 Actual loss orig 0.000408  \n",
      "error:  0.004491666 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.025469  Actual loss 0.000282 Actual loss orig 0.000282  \n",
      "error:  0.0034440095 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.015148  Actual loss 0.000195 Actual loss orig 0.000195  \n",
      "error:  0.0022681316 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.004117  Actual loss 0.000072 Actual loss orig 0.000072  \n",
      "error:  0.00078651286 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.013666  Actual loss 0.000135 Actual loss orig 0.000135  \n",
      "error:  0.0059241 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.053058  Actual loss 0.064611 Actual loss orig 0.064611    \n",
      "error:  0.7587722 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.057903 Actual loss orig 0.057903    \n",
      "error:  0.68124694 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.040182 Actual loss orig 0.040182    \n",
      "error:  0.47275972 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.041131 Actual loss orig 0.041131    \n",
      "error:  0.48391774 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.039781 Actual loss orig 0.039781  5 \n",
      "error:  0.46803278 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.036584 Actual loss orig 0.036584    \n",
      "error:  0.43042436 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.006304  Actual loss 0.041340 Actual loss orig 0.041340    \n",
      "error:  0.48658323 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220ation 05990    Train loss 0.020511  Actual loss 0.026276 Actual loss orig 0.026276    \n",
      "error:  0.31004396 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.012228  Actual loss 0.027494 Actual loss orig 0.027494    \n",
      "error:  0.32346973 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.023565  Actual loss 0.026395 Actual loss orig 0.026395    \n",
      "error:  0.3108557 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000222  Actual loss 0.035376 Actual loss orig 0.035376  9 \n",
      "error:  0.41623536 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000172  Actual loss 0.027702 Actual loss orig 0.027702    \n",
      "error:  0.32589185 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.889269  Actual loss 0.038012 Actual loss orig 0.038012   \n",
      "error:  0.44737688 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.017970 Actual loss orig 0.017970   \n",
      "error:  0.211426 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000036  Actual loss 0.014738 Actual loss orig 0.014738   \n",
      "error:  0.17339352 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000016  Actual loss 0.008212 Actual loss orig 0.008212   \n",
      "error:  0.09661194 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.007526 Actual loss orig 0.007526   \n",
      "error:  0.088550135 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.017862 Actual loss orig 0.017862   \n",
      "error:  0.21015012 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 8.364667  Actual loss 0.025512 Actual loss orig 0.025512   \n",
      "error:  0.30111986 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.024948  Actual loss 0.007676 Actual loss orig 0.007676   \n",
      "error:  0.09048409 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000079  Actual loss 0.005359 Actual loss orig 0.005359   \n",
      "error:  0.063049585 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000047  Actual loss 0.003722 Actual loss orig 0.003722   \n",
      "error:  0.043795083 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.106317  Actual loss 0.004368 Actual loss orig 0.004368   \n",
      "error:  0.051242907 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.002398 Actual loss orig 0.002398   \n",
      "error:  0.028213255 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.384824  Actual loss 0.007219 Actual loss orig 0.007219   \n",
      "error:  0.08354385 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.158044  Actual loss 0.002227 Actual loss orig 0.002227   \n",
      "error:  0.025774427 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.037656  Actual loss 0.001795 Actual loss orig 0.001795   \n",
      "error:  0.020948974 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.012503  Actual loss 0.001263 Actual loss orig 0.001263   \n",
      "error:  0.014843946 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.003417  Actual loss 0.001115 Actual loss orig 0.001115   \n",
      "error:  0.01302487 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000591  Actual loss 0.000786 Actual loss orig 0.000786   \n",
      "error:  0.009241066 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.262037  Actual loss 0.004047 Actual loss orig 0.004047  \n",
      "error:  0.046919357 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.186128  Actual loss 0.001074 Actual loss orig 0.001074  \n",
      "error:  0.012816003 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.035619  Actual loss 0.000606 Actual loss orig 0.000606  \n",
      "error:  0.007108057 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.028062  Actual loss 0.000636 Actual loss orig 0.000636  \n",
      "error:  0.007134909 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.003551  Actual loss 0.000324 Actual loss orig 0.000324  \n",
      "error:  0.0038076055 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.001398  Actual loss 0.000311 Actual loss orig 0.000311  \n",
      "error:  0.0041958457 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.742267  Actual loss 0.003644 Actual loss orig 0.003644  \n",
      "error:  0.043266933 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.102289  Actual loss 0.000681 Actual loss orig 0.000681  \n",
      "error:  0.007832683 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.050783  Actual loss 0.000431 Actual loss orig 0.000431  \n",
      "error:  0.005388374 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.018652  Actual loss 0.000282 Actual loss orig 0.000282  \n",
      "error:  0.0045350846 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.011580  Actual loss 0.000152 Actual loss orig 0.000152  \n",
      "error:  0.0017964365 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.009057  Actual loss 0.000132 Actual loss orig 0.000132  \n",
      "error:  0.001769819 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.375337  Actual loss 0.003179 Actual loss orig 0.003179  \n",
      "error:  0.036194824 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.040411  Actual loss 0.000405 Actual loss orig 0.000405  \n",
      "error:  0.0049891663 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.025836  Actual loss 0.000287 Actual loss orig 0.000287  \n",
      "error:  0.0030661845 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.018481  Actual loss 0.000217 Actual loss orig 0.000217  \n",
      "error:  0.0022807082 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.005828  Actual loss 0.000094 Actual loss orig 0.000094  \n",
      "error:  0.0011005703 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.003610  Actual loss 0.000056 Actual loss orig 0.000056  \n",
      "error:  0.0005291525 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000000  Actual loss 0.063031 Actual loss orig 0.063031    \n",
      "error:  0.74158406 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000002  Actual loss 0.042075 Actual loss orig 0.042075    \n",
      "error:  0.49503055 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.056026  Actual loss 0.040792 Actual loss orig 0.040792    \n",
      "error:  0.47928306 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.003634  Actual loss 0.043165 Actual loss orig 0.043165    \n",
      "error:  0.50780755 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000052  Actual loss 0.037259 Actual loss orig 0.037259  1 \n",
      "error:  0.43836525 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.002622  Actual loss 0.038859 Actual loss orig 0.038859    \n",
      "error:  0.45715204 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000553  Actual loss 0.060518 Actual loss orig 0.060518   \n",
      "error:  0.7120719 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.056216  Actual loss 0.031272 Actual loss orig 0.031272   \n",
      "error:  0.36788595 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.022619 Actual loss orig 0.022619    \n",
      "error:  0.2661228 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000015  Actual loss 0.018126 Actual loss orig 0.018126    \n",
      "error:  0.2132607 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000070  Actual loss 0.024515 Actual loss orig 0.024515  3 \n",
      "error:  0.28843594 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000005  Actual loss 0.028735 Actual loss orig 0.028735    \n",
      "error:  0.33809415 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.237599  Actual loss 0.043258 Actual loss orig 0.043258   \n",
      "error:  0.51129395 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.030476  Actual loss 0.020988 Actual loss orig 0.020988   \n",
      "error:  0.24714611 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.003416  Actual loss 0.013756 Actual loss orig 0.013756   \n",
      "error:  0.16197795 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 05990    Train loss 0.000817  Actual loss 0.007718 Actual loss orig 0.007718   \n",
      "error:  0.09087409 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000001  Actual loss 0.007639 Actual loss orig 0.007639   \n",
      "error:  0.08987384 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.015723  Actual loss 0.008214 Actual loss orig 0.008214   \n",
      "error:  0.09695375 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 3.463509  Actual loss 0.015152 Actual loss orig 0.015152   \n",
      "error:  0.17801379 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.326730  Actual loss 0.008364 Actual loss orig 0.008364   \n",
      "error:  0.09651517 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.011716  Actual loss 0.005539 Actual loss orig 0.005539   \n",
      "error:  0.06564295 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.001291  Actual loss 0.003823 Actual loss orig 0.003823   \n",
      "error:  0.04494433 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000025  Actual loss 0.003450 Actual loss orig 0.003450   \n",
      "error:  0.04059647 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.002608 Actual loss orig 0.002608   \n",
      "error:  0.030679114 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 4.681767  Actual loss 0.012347 Actual loss orig 0.012347   \n",
      "error:  0.14271402 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.160681  Actual loss 0.001891 Actual loss orig 0.001891   \n",
      "error:  0.022556642 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.025236  Actual loss 0.001653 Actual loss orig 0.001653   \n",
      "error:  0.019876113 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.014260  Actual loss 0.001364 Actual loss orig 0.001364   \n",
      "error:  0.015922014 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.002886  Actual loss 0.000997 Actual loss orig 0.000997   \n",
      "error:  0.011703917 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000710  Actual loss 0.001018 Actual loss orig 0.001018   \n",
      "error:  0.011973941 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.705034  Actual loss 0.005825 Actual loss orig 0.005825  \n",
      "error:  0.06737704 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.145966  Actual loss 0.001014 Actual loss orig 0.001014  \n",
      "error:  0.012027091 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.066572  Actual loss 0.000724 Actual loss orig 0.000724  \n",
      "error:  0.008406191 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.041318  Actual loss 0.000572 Actual loss orig 0.000572  \n",
      "error:  0.006644857 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.022842  Actual loss 0.000484 Actual loss orig 0.000484  \n",
      "error:  0.005431592 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.208015  Actual loss 0.000738 Actual loss orig 0.000738  \n",
      "error:  0.0061706314 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.558746  Actual loss 0.002669 Actual loss orig 0.002669  \n",
      "error:  0.031384673 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.081146  Actual loss 0.000582 Actual loss orig 0.000582  \n",
      "error:  0.00853119 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.044108  Actual loss 0.000374 Actual loss orig 0.000374  \n",
      "error:  0.0041318624 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.045063  Actual loss 0.000398 Actual loss orig 0.000398  \n",
      "error:  0.0048652124 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.008030  Actual loss 0.000164 Actual loss orig 0.000164  \n",
      "error:  0.0019417714 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.002246  Actual loss 0.000111 Actual loss orig 0.000111  \n",
      "error:  0.002341883 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.391775  Actual loss 0.003354 Actual loss orig 0.003354  \n",
      "error:  0.03743075 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.047923  Actual loss 0.000464 Actual loss orig 0.000464  \n",
      "error:  0.0051205507 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.035070  Actual loss 0.000381 Actual loss orig 0.000381  \n",
      "error:  0.003642674 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.014958  Actual loss 0.000182 Actual loss orig 0.000182  \n",
      "error:  0.0020029605 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.005029  Actual loss 0.000084 Actual loss orig 0.000084  \n",
      "error:  0.0009970381 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.004133  Actual loss 0.000060 Actual loss orig 0.000060  \n",
      "error:  0.00068495393 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000000  Actual loss 0.052145 Actual loss orig 0.052145    \n",
      "error:  0.61350083 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000216  Actual loss 0.045735 Actual loss orig 0.045735    \n",
      "error:  0.53811747 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000001  Actual loss 0.034454 Actual loss orig 0.034454    \n",
      "error:  0.405379 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000151  Actual loss 0.033787 Actual loss orig 0.033787    \n",
      "error:  0.39746153 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001181  Actual loss 0.059007 Actual loss orig 0.059007  9 \n",
      "error:  0.6941022 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000004  Actual loss 0.063284 Actual loss orig 0.063284    \n",
      "error:  0.74453646 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.003489  Actual loss 0.044574 Actual loss orig 0.044574    \n",
      "error:  0.5246197 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.556905  Actual loss 0.024140 Actual loss orig 0.024140    \n",
      "error:  0.28413662 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000002  Actual loss 0.024811 Actual loss orig 0.024811    \n",
      "error:  0.2919073 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000032  Actual loss 0.022834 Actual loss orig 0.022834    \n",
      "error:  0.26863784 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000005  Actual loss 0.026354 Actual loss orig 0.026354  8 \n",
      "error:  0.310063 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.015471 Actual loss orig 0.015471  6 \n",
      "error:  0.18202244 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 5.033640  Actual loss 0.044353 Actual loss orig 0.044353   \n",
      "error:  0.51809186 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000461  Actual loss 0.016086 Actual loss orig 0.016086   \n",
      "error:  0.18928292 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.034098  Actual loss 0.012060 Actual loss orig 0.012060   \n",
      "error:  0.14213432 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.018949  Actual loss 0.012587 Actual loss orig 0.012587   \n",
      "error:  0.14784373 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000584  Actual loss 0.007969 Actual loss orig 0.007969   \n",
      "error:  0.09374485 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.016138 Actual loss orig 0.016138   \n",
      "error:  0.18987161 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 9.199946  Actual loss 0.028505 Actual loss orig 0.028505   \n",
      "error:  0.33528247 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.032378  Actual loss 0.011405 Actual loss orig 0.011405   \n",
      "error:  0.13496992 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.005373  Actual loss 0.005211 Actual loss orig 0.005211   \n",
      "error:  0.06142038 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000001  Actual loss 0.004394 Actual loss orig 0.004394   \n",
      "error:  0.05169723 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.028478  Actual loss 0.001716 Actual loss orig 0.001716   \n",
      "error:  0.02037326 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.021857  Actual loss 0.002031 Actual loss orig 0.002031   \n",
      "error:  0.023765728 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.411205  Actual loss 0.006101 Actual loss orig 0.006101   \n",
      "error:  0.07067881 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.133860  Actual loss 0.002497 Actual loss orig 0.002497   \n",
      "error:  0.02981324 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.111984  Actual loss 0.001787 Actual loss orig 0.001787   \n",
      "error:  0.020737723 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 1.794019  Actual loss 0.002660 Actual loss orig 0.002660   \n",
      "error:  0.020377701 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000055  Actual loss 0.001188 Actual loss orig 0.001188   \n",
      "error:  0.013977661 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.012798  Actual loss 0.000807 Actual loss orig 0.000807   \n",
      "error:  0.0094461255 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.229873  Actual loss 0.003860 Actual loss orig 0.003860  \n",
      "error:  0.04548909 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.175698  Actual loss 0.000943 Actual loss orig 0.000943  \n",
      "error:  0.011508073 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.061849  Actual loss 0.000795 Actual loss orig 0.000795  \n",
      "error:  0.00940891 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.012178  Actual loss 0.000476 Actual loss orig 0.000476  \n",
      "error:  0.0057733436 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.019428  Actual loss 0.000424 Actual loss orig 0.000424  \n",
      "error:  0.0059113614 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000652  Actual loss 0.000377 Actual loss orig 0.000377  \n",
      "error:  0.004435192 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.106714  Actual loss 0.005430 Actual loss orig 0.005430  \n",
      "error:  0.06480791 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.088631  Actual loss 0.000596 Actual loss orig 0.000596  \n",
      "error:  0.0075445296 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.077955  Actual loss 0.000543 Actual loss orig 0.000543  \n",
      "error:  0.005059597 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.078745  Actual loss 0.000510 Actual loss orig 0.000510  \n",
      "error:  0.004696228 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.006506  Actual loss 0.000134 Actual loss orig 0.000134  \n",
      "error:  0.001569796 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.007903  Actual loss 0.000134 Actual loss orig 0.000134  \n",
      "error:  0.0015793394 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.209105  Actual loss 0.001768 Actual loss orig 0.001768  \n",
      "error:  0.021091418 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.053101  Actual loss 0.000502 Actual loss orig 0.000502  \n",
      "error:  0.00740342 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.027328  Actual loss 0.000294 Actual loss orig 0.000294  \n",
      "error:  0.0030735296 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.029435  Actual loss 0.000298 Actual loss orig 0.000298  \n",
      "error:  0.00229422 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.008478  Actual loss 0.000110 Actual loss orig 0.000110  \n",
      "error:  0.0013450725 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.017812  Actual loss 0.000180 Actual loss orig 0.000180  \n",
      "error:  0.0013629809 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.048563  Actual loss 0.073695 Actual loss orig 0.073695    \n",
      "error:  0.8658324 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.495975  Actual loss 0.045093 Actual loss orig 0.045093    \n",
      "error:  0.5284709 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.010994  Actual loss 0.033554 Actual loss orig 0.033554    \n",
      "error:  0.39397648 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13050tion 05990    Train loss 0.003525  Actual loss 0.038540 Actual loss orig 0.038540    \n",
      "error:  0.45383587 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.468053  Actual loss 0.037683 Actual loss orig 0.037683  6 \n",
      "error:  0.4464506 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.063084 Actual loss orig 0.063084    \n",
      "error:  0.74220514 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.092043  Actual loss 0.058242 Actual loss orig 0.058242    \n",
      "error:  0.68552244 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000117  Actual loss 0.028917 Actual loss orig 0.028917    \n",
      "error:  0.34028015 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.023683 Actual loss orig 0.023683   \n",
      "error:  0.27863318 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.017071 Actual loss orig 0.017071    \n",
      "error:  0.20084198 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.135033  Actual loss 0.023840 Actual loss orig 0.023840  9 \n",
      "error:  0.28415728 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.029125 Actual loss orig 0.029125    \n",
      "error:  0.34266514 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.352357  Actual loss 0.041503 Actual loss orig 0.041503   \n",
      "error:  0.48746565 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.012924  Actual loss 0.020136 Actual loss orig 0.020136   \n",
      "error:  0.23683356 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000086  Actual loss 0.011613 Actual loss orig 0.011613   \n",
      "error:  0.13663878 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.027060  Actual loss 0.010403 Actual loss orig 0.010403   \n",
      "error:  0.122754894 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.016352  Actual loss 0.011713 Actual loss orig 0.011713   \n",
      "error:  0.13941282 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.009188  Actual loss 0.008553 Actual loss orig 0.008553   \n",
      "error:  0.10058144 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 6.166874  Actual loss 0.027254 Actual loss orig 0.027254   \n",
      "error:  0.32918084 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.015271  Actual loss 0.007183 Actual loss orig 0.007183   \n",
      "error:  0.08549701 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.002562  Actual loss 0.006653 Actual loss orig 0.006653   \n",
      "error:  0.07830218 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.001809  Actual loss 0.003817 Actual loss orig 0.003817   \n",
      "error:  0.04493861 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.036262  Actual loss 0.003088 Actual loss orig 0.003088   \n",
      "error:  0.036833346 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.004712  Actual loss 0.002224 Actual loss orig 0.002224   \n",
      "error:  0.026247026 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 3.748582  Actual loss 0.009611 Actual loss orig 0.009611   \n",
      "error:  0.11242283 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.174077  Actual loss 0.002482 Actual loss orig 0.002482   \n",
      "error:  0.029840983 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.069301  Actual loss 0.001553 Actual loss orig 0.001553   \n",
      "error:  0.017798975 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.030413  Actual loss 0.001193 Actual loss orig 0.001193   \n",
      "error:  0.013920476 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.148773  Actual loss 0.000990 Actual loss orig 0.000990   \n",
      "error:  0.0115164835 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.270942  Actual loss 0.000975 Actual loss orig 0.000975   \n",
      "error:  0.010200855 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.463586  Actual loss 0.005178 Actual loss orig 0.005178  \n",
      "error:  0.06426485 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.176003  Actual loss 0.001125 Actual loss orig 0.001125  \n",
      "error:  0.012847114 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.068528  Actual loss 0.000689 Actual loss orig 0.000689  \n",
      "error:  0.0077744583 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.018809  Actual loss 0.000523 Actual loss orig 0.000523  \n",
      "error:  0.006104745 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001343  Actual loss 0.000466 Actual loss orig 0.000466  \n",
      "error:  0.0054787495 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.020782  Actual loss 0.000448 Actual loss orig 0.000448  \n",
      "error:  0.004955137 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.972546  Actual loss 0.004650 Actual loss orig 0.004650  \n",
      "error:  0.052645013 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.138874  Actual loss 0.000849 Actual loss orig 0.000849  \n",
      "error:  0.008786775 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.038392  Actual loss 0.000384 Actual loss orig 0.000384  \n",
      "error:  0.005216313 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.017746  Actual loss 0.000270 Actual loss orig 0.000270  \n",
      "error:  0.00512378 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.039786  Actual loss 0.000253 Actual loss orig 0.000253  \n",
      "error:  0.0024573694 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.014530  Actual loss 0.000167 Actual loss orig 0.000167  \n",
      "error:  0.0018650888 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.269960  Actual loss 0.002280 Actual loss orig 0.002280  \n",
      "error:  0.024909278 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.054213  Actual loss 0.000545 Actual loss orig 0.000545  \n",
      "error:  0.0062319245 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.021077  Actual loss 0.000271 Actual loss orig 0.000271  \n",
      "error:  0.0034740581 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.013637  Actual loss 0.000189 Actual loss orig 0.000189  \n",
      "error:  0.0022101344 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.005047  Actual loss 0.000081 Actual loss orig 0.000081  \n",
      "error:  0.0008603843 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.129407  Actual loss 0.001004 Actual loss orig 0.001004  \n",
      "error:  0.009344562 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000015  Actual loss 0.056786 Actual loss orig 0.056786    \n",
      "error:  0.66809493 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.022340  Actual loss 0.030415 Actual loss orig 0.030415    \n",
      "error:  0.3571989 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.044904 Actual loss orig 0.044904    \n",
      "error:  0.52831423 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.034740 Actual loss orig 0.034740    \n",
      "error:  0.4087253 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000619  Actual loss 0.070273 Actual loss orig 0.070273  8 \n",
      "error:  0.8270271 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.024484 Actual loss orig 0.024484    \n",
      "error:  0.28806138 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 7.063344  Actual loss 0.044634 Actual loss orig 0.044634    \n",
      "error:  0.5154227 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.037083 Actual loss orig 0.037083    \n",
      "error:  0.4362952 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.023541 Actual loss orig 0.023541   \n",
      "error:  0.27696458 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000001  Actual loss 0.018016 Actual loss orig 0.018016    \n",
      "error:  0.21196541 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000170  Actual loss 0.021506 Actual loss orig 0.021506  0 \n",
      "error:  0.2530267 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.022071 Actual loss orig 0.022071    \n",
      "error:  0.2596673 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.242336  Actual loss 0.055568 Actual loss orig 0.055568   \n",
      "error:  0.65380096 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.004935  Actual loss 0.014974 Actual loss orig 0.014974   \n",
      "error:  0.17623265 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000004  Actual loss 0.011794 Actual loss orig 0.011794   \n",
      "error:  0.13875946 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.003583  Actual loss 0.010322 Actual loss orig 0.010322   \n",
      "error:  0.12136553 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.019440 Actual loss orig 0.019440   \n",
      "error:  0.22871931 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.026643  Actual loss 0.013763 Actual loss orig 0.013763   \n",
      "error:  0.16182332 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 3.949508  Actual loss 0.017943 Actual loss orig 0.017943   \n",
      "error:  0.21021228 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.071068  Actual loss 0.006209 Actual loss orig 0.006209   \n",
      "error:  0.072755344 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.018951  Actual loss 0.004323 Actual loss orig 0.004323   \n",
      "error:  0.05085784 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.003537 Actual loss orig 0.003537   \n",
      "error:  0.041611258 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000521  Actual loss 0.004786 Actual loss orig 0.004786   \n",
      "error:  0.056337256 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000737  Actual loss 0.002069 Actual loss orig 0.002069   \n",
      "error:  0.024361752 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 4.604802  Actual loss 0.013118 Actual loss orig 0.013118   \n",
      "error:  0.15265746 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.188881  Actual loss 0.003274 Actual loss orig 0.003274   \n",
      "error:  0.03873134 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.032116  Actual loss 0.001608 Actual loss orig 0.001608   \n",
      "error:  0.01999934 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.002320  Actual loss 0.001398 Actual loss orig 0.001398   \n",
      "error:  0.016763523 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001467  Actual loss 0.001202 Actual loss orig 0.001202   \n",
      "error:  0.015077957 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000998  Actual loss 0.000915 Actual loss orig 0.000915   \n",
      "error:  0.010778787 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.325389  Actual loss 0.003969 Actual loss orig 0.003969  \n",
      "error:  0.046993293 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.213808  Actual loss 0.001143 Actual loss orig 0.001143  \n",
      "error:  0.012450596 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.068646  Actual loss 0.000790 Actual loss orig 0.000790  \n",
      "error:  0.009466033 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.020734  Actual loss 0.000516 Actual loss orig 0.000516  \n",
      "error:  0.005886574 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.076482  Actual loss 0.000452 Actual loss orig 0.000452  \n",
      "error:  0.0045166747 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.019824  Actual loss 0.000346 Actual loss orig 0.000346  \n",
      "error:  0.0047972123 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.470086  Actual loss 0.002343 Actual loss orig 0.002343  \n",
      "error:  0.0314384 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.086531  Actual loss 0.000600 Actual loss orig 0.000600  \n",
      "error:  0.007779292 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830ation 05990    Train loss 0.061013  Actual loss 0.000448 Actual loss orig 0.000448  \n",
      "error:  0.004632018 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.024501  Actual loss 0.000300 Actual loss orig 0.000300  \n",
      "error:  0.0033506656 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.006823  Actual loss 0.000139 Actual loss orig 0.000139  \n",
      "error:  0.0015225598 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.025419  Actual loss 0.000209 Actual loss orig 0.000209  \n",
      "error:  0.0032811428 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.560378  Actual loss 0.004725 Actual loss orig 0.004725  \n",
      "error:  0.05560334 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.048827  Actual loss 0.000496 Actual loss orig 0.000496  \n",
      "error:  0.006479543 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.027158  Actual loss 0.000300 Actual loss orig 0.000300  \n",
      "error:  0.0034378674 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.012154  Actual loss 0.000160 Actual loss orig 0.000160  \n",
      "error:  0.0020641366 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.004368  Actual loss 0.000073 Actual loss orig 0.000073  \n",
      "error:  0.0007612649 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.004024  Actual loss 0.000069 Actual loss orig 0.000069  \n",
      "error:  0.0039240937 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000000  Actual loss 0.057925 Actual loss orig 0.057925    \n",
      "error:  0.68150246 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000001  Actual loss 0.044756 Actual loss orig 0.044756    \n",
      "error:  0.5265658 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.001112  Actual loss 0.039893 Actual loss orig 0.039893    \n",
      "error:  0.46923092 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.001086  Actual loss 0.036519 Actual loss orig 0.036519    \n",
      "error:  0.42968306 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.004898  Actual loss 0.051153 Actual loss orig 0.051153  1 \n",
      "error:  0.5995291 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.005250  Actual loss 0.031548 Actual loss orig 0.031548  8 \n",
      "error:  0.37124103 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.000317  Actual loss 0.040604 Actual loss orig 0.040604    \n",
      "error:  0.47746757 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.037105 Actual loss orig 0.037105    \n",
      "error:  0.43655384 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.039655  Actual loss 0.026575 Actual loss orig 0.026575    \n",
      "error:  0.31268206 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000026  Actual loss 0.020338 Actual loss orig 0.020338    \n",
      "error:  0.23912644 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000001  Actual loss 0.023987 Actual loss orig 0.023987  1 \n",
      "error:  0.2822072 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000016  Actual loss 0.049301 Actual loss orig 0.049301    \n",
      "error:  0.5800242 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.925420  Actual loss 0.054709 Actual loss orig 0.054709   \n",
      "error:  0.6412869 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000034  Actual loss 0.013906 Actual loss orig 0.013906   \n",
      "error:  0.1636034 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.010447 Actual loss orig 0.010447   \n",
      "error:  0.12291391 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.010751 Actual loss orig 0.010751   \n",
      "error:  0.12648416 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000025  Actual loss 0.008226 Actual loss orig 0.008226   \n",
      "error:  0.096782595 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.006110 Actual loss orig 0.006110   \n",
      "error:  0.07189187 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610ration 05990    Train loss 4.230757  Actual loss 0.019576 Actual loss orig 0.019576   \n",
      "error:  0.23331082 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.038919  Actual loss 0.007706 Actual loss orig 0.007706   \n",
      "error:  0.09102468 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.003277  Actual loss 0.004015 Actual loss orig 0.004015   \n",
      "error:  0.047211885 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.270448  Actual loss 0.004737 Actual loss orig 0.004737   \n",
      "error:  0.054620083 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000073  Actual loss 0.004892 Actual loss orig 0.004892   \n",
      "error:  0.057561047 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.072709  Actual loss 0.002716 Actual loss orig 0.002716   \n",
      "error:  0.03500508 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 4.554068  Actual loss 0.011381 Actual loss orig 0.011381   \n",
      "error:  0.13390455 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.198269  Actual loss 0.002435 Actual loss orig 0.002435   \n",
      "error:  0.028683076 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.010019  Actual loss 0.001975 Actual loss orig 0.001975   \n",
      "error:  0.023350285 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.019867  Actual loss 0.001467 Actual loss orig 0.001467   \n",
      "error:  0.017212037 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001298  Actual loss 0.000998 Actual loss orig 0.000998   \n",
      "error:  0.011862653 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000002  Actual loss 0.000969 Actual loss orig 0.000969   \n",
      "error:  0.011405105 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.857267  Actual loss 0.002585 Actual loss orig 0.002585  \n",
      "error:  0.030421305 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.173740  Actual loss 0.001026 Actual loss orig 0.001026  \n",
      "error:  0.011584422 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.097245  Actual loss 0.000767 Actual loss orig 0.000767  \n",
      "error:  0.008495173 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.026215  Actual loss 0.000713 Actual loss orig 0.000713  \n",
      "error:  0.00823328 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.002353  Actual loss 0.000415 Actual loss orig 0.000415  \n",
      "error:  0.0048931665 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.005265  Actual loss 0.000334 Actual loss orig 0.000334  \n",
      "error:  0.0039153066 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.080908  Actual loss 0.010184 Actual loss orig 0.010184  \n",
      "error:  0.11773221 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.104385  Actual loss 0.000645 Actual loss orig 0.000645  \n",
      "error:  0.0067142826 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.044510  Actual loss 0.000424 Actual loss orig 0.000424  \n",
      "error:  0.0045720856 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.046863  Actual loss 0.000357 Actual loss orig 0.000357  \n",
      "error:  0.0031804808 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.003962  Actual loss 0.000122 Actual loss orig 0.000122  \n",
      "error:  0.00139578 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.013226  Actual loss 0.000186 Actual loss orig 0.000186  \n",
      "error:  0.002850462 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.312883  Actual loss 0.002599 Actual loss orig 0.002599  \n",
      "error:  0.03005347 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.077221  Actual loss 0.000692 Actual loss orig 0.000692  \n",
      "error:  0.006240633 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.035844  Actual loss 0.000371 Actual loss orig 0.000371  \n",
      "error:  0.0037781426 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.010478  Actual loss 0.000154 Actual loss orig 0.000154  \n",
      "error:  0.0028990342 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.007418  Actual loss 0.000098 Actual loss orig 0.000098  \n",
      "error:  0.0010148546 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.002131  Actual loss 0.000045 Actual loss orig 0.000045  \n",
      "error:  0.000921424 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.572640  Actual loss 0.055364 Actual loss orig 0.055364    \n",
      "error:  0.6470693 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000008  Actual loss 0.043690 Actual loss orig 0.043690    \n",
      "error:  0.51401305 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.032084 Actual loss orig 0.032084    \n",
      "error:  0.377474 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.220061  Actual loss 0.046253 Actual loss orig 0.046253    \n",
      "error:  0.5447156 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.048128 Actual loss orig 0.048128  6 \n",
      "error:  0.5662469 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.356068  Actual loss 0.045975 Actual loss orig 0.045975    \n",
      "error:  0.5344449 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.035782  Actual loss 0.060838 Actual loss orig 0.060838    \n",
      "error:  0.71446687 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000103  Actual loss 0.026908 Actual loss orig 0.026908   \n",
      "error:  0.31660238 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000001  Actual loss 0.026213 Actual loss orig 0.026213    \n",
      "error:  0.3084093 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.022424 Actual loss orig 0.022424    \n",
      "error:  0.26382703 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.026549 Actual loss orig 0.026549    \n",
      "error:  0.31236333 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.012915 Actual loss orig 0.012915    \n",
      "error:  0.1519477 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.381973  Actual loss 0.045416 Actual loss orig 0.045416   \n",
      "error:  0.5406471 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.060619  Actual loss 0.014789 Actual loss orig 0.014789   \n",
      "error:  0.1739394 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000121  Actual loss 0.012841 Actual loss orig 0.012841   \n",
      "error:  0.15109207 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.010731 Actual loss orig 0.010731   \n",
      "error:  0.1262567 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000011  Actual loss 0.009113 Actual loss orig 0.009113   \n",
      "error:  0.10709348 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000587  Actual loss 0.009628 Actual loss orig 0.009628   \n",
      "error:  0.1138044 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 5.865678  Actual loss 0.020203 Actual loss orig 0.020203   \n",
      "error:  0.23962444 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.036395  Actual loss 0.011232 Actual loss orig 0.011232   \n",
      "error:  0.13274623 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.029671  Actual loss 0.005214 Actual loss orig 0.005214   \n",
      "error:  0.06125749 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.003348  Actual loss 0.003680 Actual loss orig 0.003680   \n",
      "error:  0.04331287 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.448341  Actual loss 0.003417 Actual loss orig 0.003417   \n",
      "error:  0.03868741 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.002788 Actual loss orig 0.002788   \n",
      "error:  0.032805014 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 11.657404  Actual loss 0.022307 Actual loss orig 0.022307  \n",
      "error:  0.2603503 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.126459  Actual loss 0.002004 Actual loss orig 0.002004   \n",
      "error:  0.023506029 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.022630  Actual loss 0.001990 Actual loss orig 0.001990   \n",
      "error:  0.02338741 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.001599  Actual loss 0.001287 Actual loss orig 0.001287   \n",
      "error:  0.015101366 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000018  Actual loss 0.000945 Actual loss orig 0.000945   \n",
      "error:  0.011118898 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.017465  Actual loss 0.000818 Actual loss orig 0.000818   \n",
      "error:  0.009488597 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 1.298167  Actual loss 0.003995 Actual loss orig 0.003995  \n",
      "error:  0.04635219 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.136189  Actual loss 0.000898 Actual loss orig 0.000898  \n",
      "error:  0.010319529 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.114217  Actual loss 0.000823 Actual loss orig 0.000823  \n",
      "error:  0.012329027 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.031134  Actual loss 0.000603 Actual loss orig 0.000603  \n",
      "error:  0.006756563 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.003668  Actual loss 0.000410 Actual loss orig 0.000410  \n",
      "error:  0.004777459 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.013258  Actual loss 0.000283 Actual loss orig 0.000283  \n",
      "error:  0.0031956634 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.948123  Actual loss 0.004572 Actual loss orig 0.004572  \n",
      "error:  0.053430866 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.087238  Actual loss 0.000598 Actual loss orig 0.000598  \n",
      "error:  0.0070783547 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.037062  Actual loss 0.000374 Actual loss orig 0.000374  \n",
      "error:  0.0050159246 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.028494  Actual loss 0.000311 Actual loss orig 0.000311  \n",
      "error:  0.0034881835 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.005463  Actual loss 0.000157 Actual loss orig 0.000157  \n",
      "error:  0.0022559562 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.013881  Actual loss 0.000166 Actual loss orig 0.000166  \n",
      "error:  0.0016146357 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.726485  Actual loss 0.006147 Actual loss orig 0.006147  \n",
      "error:  0.07082621 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.046704  Actual loss 0.000491 Actual loss orig 0.000491  \n",
      "error:  0.0062012 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.028593  Actual loss 0.000320 Actual loss orig 0.000320  \n",
      "error:  0.0043718745 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.014152  Actual loss 0.000182 Actual loss orig 0.000182  \n",
      "error:  0.001984658 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.005761  Actual loss 0.000087 Actual loss orig 0.000087  \n",
      "error:  0.00094666856 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.013042  Actual loss 0.000146 Actual loss orig 0.000146  \n",
      "error:  0.0017062381 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.228138  Actual loss 0.055774 Actual loss orig 0.055774    \n",
      "error:  0.6555877 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000421  Actual loss 0.041151 Actual loss orig 0.041151    \n",
      "error:  0.4840537 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 2.292119  Actual loss 0.056135 Actual loss orig 0.056135    \n",
      "error:  0.65177333 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.025465 Actual loss orig 0.025465    \n",
      "error:  0.29960793 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.208164  Actual loss 0.033627 Actual loss orig 0.033627  3 \n",
      "error:  0.3996662 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.015685  Actual loss 0.055495 Actual loss orig 0.055495  7 \n",
      "error:  0.6541137 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610ration 05990    Train loss 0.000102  Actual loss 0.060542 Actual loss orig 0.060542    \n",
      "error:  0.71233785 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.000000  Actual loss 0.024993 Actual loss orig 0.024993   \n",
      "error:  0.29404902 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000000  Actual loss 0.020076 Actual loss orig 0.020076    \n",
      "error:  0.23620261 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000017  Actual loss 0.018491 Actual loss orig 0.018491    \n",
      "error:  0.2175336 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000815  Actual loss 0.032993 Actual loss orig 0.032993  3 \n",
      "error:  0.38828787 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.027629 Actual loss orig 0.027629    \n",
      "error:  0.32506156 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.887183  Actual loss 0.044812 Actual loss orig 0.044812   \n",
      "error:  0.5314215 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.002284  Actual loss 0.013731 Actual loss orig 0.013731   \n",
      "error:  0.1630044 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.001148  Actual loss 0.011261 Actual loss orig 0.011261   \n",
      "error:  0.13246621 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.009882 Actual loss orig 0.009882   \n",
      "error:  0.11626493 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.200622  Actual loss 0.008077 Actual loss orig 0.008077   \n",
      "error:  0.09575112 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000085  Actual loss 0.006902 Actual loss orig 0.006902   \n",
      "error:  0.0812337 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 3.504804  Actual loss 0.015198 Actual loss orig 0.015198   \n",
      "error:  0.17636053 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.007122  Actual loss 0.006343 Actual loss orig 0.006343   \n",
      "error:  0.07485565 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.015453  Actual loss 0.004820 Actual loss orig 0.004820   \n",
      "error:  0.05675401 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.007181  Actual loss 0.003627 Actual loss orig 0.003627   \n",
      "error:  0.042629126 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000962  Actual loss 0.004008 Actual loss orig 0.004008   \n",
      "error:  0.047149993 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.003058  Actual loss 0.002671 Actual loss orig 0.002671   \n",
      "error:  0.031357367 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 6.993549  Actual loss 0.013400 Actual loss orig 0.013400   \n",
      "error:  0.15103354 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.152570  Actual loss 0.002042 Actual loss orig 0.002042   \n",
      "error:  0.023911873 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.030720  Actual loss 0.001922 Actual loss orig 0.001922   \n",
      "error:  0.022775004 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.002255  Actual loss 0.001266 Actual loss orig 0.001266   \n",
      "error:  0.014898371 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000448  Actual loss 0.000984 Actual loss orig 0.000984   \n",
      "error:  0.011596571 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.108900  Actual loss 0.000809 Actual loss orig 0.000809   \n",
      "error:  0.0088279825 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.571365  Actual loss 0.007919 Actual loss orig 0.007919  \n",
      "error:  0.089668624 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.169971  Actual loss 0.001104 Actual loss orig 0.001104  \n",
      "error:  0.012688929 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.086642  Actual loss 0.000859 Actual loss orig 0.000859  \n",
      "error:  0.009653631 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.054678  Actual loss 0.000568 Actual loss orig 0.000568  \n",
      "error:  0.009071425 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.035397  Actual loss 0.000476 Actual loss orig 0.000476  \n",
      "error:  0.005127462 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.004449  Actual loss 0.000328 Actual loss orig 0.000328  \n",
      "error:  0.0038400232 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.575950  Actual loss 0.002858 Actual loss orig 0.002858  \n",
      "error:  0.03476223 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.104655  Actual loss 0.000709 Actual loss orig 0.000709  \n",
      "error:  0.008643105 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.035688  Actual loss 0.000362 Actual loss orig 0.000362  \n",
      "error:  0.004214913 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.058087  Actual loss 0.000415 Actual loss orig 0.000415  \n",
      "error:  0.0040675644 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.007071  Actual loss 0.000143 Actual loss orig 0.000143  \n",
      "error:  0.0015787145 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.007859  Actual loss 0.000134 Actual loss orig 0.000134  \n",
      "error:  0.0015941795 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.583126  Actual loss 0.004963 Actual loss orig 0.004963  \n",
      "error:  0.057993688 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.046896  Actual loss 0.000482 Actual loss orig 0.000482  \n",
      "error:  0.0060530426 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.022000  Actual loss 0.000268 Actual loss orig 0.000268  \n",
      "error:  0.0031817723 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.013558  Actual loss 0.000182 Actual loss orig 0.000182  \n",
      "error:  0.0018671331 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.006245  Actual loss 0.000101 Actual loss orig 0.000101  \n",
      "error:  0.0011559404 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.003499  Actual loss 0.000061 Actual loss orig 0.000061  \n",
      "error:  0.0013380802 \n",
      "\n",
      "number useful variables / number observations 4.1\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 8.840269  Actual loss 0.061122 Actual loss orig 0.061122    \n",
      "error:  0.7186566 \n",
      "\n",
      "number useful variables / number observations 16.2\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.011330  Actual loss 0.038458 Actual loss orig 0.038458    \n",
      "error:  0.45251235 \n",
      "\n",
      "number useful variables / number observations 36.3\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.000031  Actual loss 0.040156 Actual loss orig 0.040156    \n",
      "error:  0.47244817 \n",
      "\n",
      "number useful variables / number observations 100.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000000  Actual loss 0.040027 Actual loss orig 0.040027    \n",
      "error:  0.47092712 \n",
      "\n",
      "number useful variables / number observations 901.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000056  Actual loss 0.050449 Actual loss orig 0.050449  4 \n",
      "error:  0.59355736 \n",
      "\n",
      "number useful variables / number observations 2502.5\n",
      "number observations / number of variables 0.006103515625\n",
      "m,n,nump 100 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.002788  Actual loss 0.048912 Actual loss orig 0.048912  3 \n",
      "error:  0.5754149 \n",
      "\n",
      "number useful variables / number observations 2.0707070707070705\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 14.772470  Actual loss 0.069807 Actual loss orig 0.069807   \n",
      "error:  0.8525464 \n",
      "\n",
      "number useful variables / number observations 8.181818181818182\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.001284  Actual loss 0.033671 Actual loss orig 0.033671    \n",
      "error:  0.39615968 \n",
      "\n",
      "number useful variables / number observations 18.333333333333332\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.155081  Actual loss 0.019778 Actual loss orig 0.019778    \n",
      "error:  0.23269519 \n",
      "\n",
      "number useful variables / number observations 50.75757575757576\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000271  Actual loss 0.018591 Actual loss orig 0.018591    \n",
      "error:  0.21882032 \n",
      "\n",
      "number useful variables / number observations 455.3030303030303\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000004  Actual loss 0.024781 Actual loss orig 0.024781  0 \n",
      "error:  0.29154503 \n",
      "\n",
      "number useful variables / number observations 1263.888888888889\n",
      "number observations / number of variables 0.0120849609375\n",
      "m,n,nump 198 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.017189  Actual loss 0.031180 Actual loss orig 0.031180    \n",
      "error:  0.3668862 \n",
      "\n",
      "number useful variables / number observations 1.0379746835443038\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.609972  Actual loss 0.052200 Actual loss orig 0.052200   \n",
      "error:  0.6088614 \n",
      "\n",
      "number useful variables / number observations 4.10126582278481\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 1.065100  Actual loss 0.016228 Actual loss orig 0.016228   \n",
      "error:  0.19371511 \n",
      "\n",
      "number useful variables / number observations 9.189873417721518\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830ation 05990    Train loss 0.000000  Actual loss 0.007663 Actual loss orig 0.007663   \n",
      "error:  0.09015827 \n",
      "\n",
      "number useful variables / number observations 25.443037974683545\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.000002  Actual loss 0.008246 Actual loss orig 0.008246   \n",
      "error:  0.0970191 \n",
      "\n",
      "number useful variables / number observations 228.22784810126583\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000008  Actual loss 0.007714 Actual loss orig 0.007714   \n",
      "error:  0.09076037 \n",
      "\n",
      "number useful variables / number observations 633.5443037974684\n",
      "number observations / number of variables 0.02410888671875\n",
      "m,n,nump 395 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.005559 Actual loss orig 0.005559   \n",
      "error:  0.06539877 \n",
      "\n",
      "number useful variables / number observations 0.5216284987277354\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 5.320463  Actual loss 0.023719 Actual loss orig 0.023719   \n",
      "error:  0.28102773 \n",
      "\n",
      "number useful variables / number observations 2.0610687022900764\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.016167  Actual loss 0.006092 Actual loss orig 0.006092   \n",
      "error:  0.0716616 \n",
      "\n",
      "number useful variables / number observations 4.6183206106870225\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.280501  Actual loss 0.005056 Actual loss orig 0.005056   \n",
      "error:  0.05961311 \n",
      "\n",
      "number useful variables / number observations 12.786259541984732\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.041701  Actual loss 0.003130 Actual loss orig 0.003130   \n",
      "error:  0.036591742 \n",
      "\n",
      "number useful variables / number observations 114.69465648854961\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000000  Actual loss 0.005366 Actual loss orig 0.005366   \n",
      "error:  0.063135706 \n",
      "\n",
      "number useful variables / number observations 318.38422391857506\n",
      "number observations / number of variables 0.0479736328125\n",
      "m,n,nump 786 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000000  Actual loss 0.002489 Actual loss orig 0.002489   \n",
      "error:  0.029288657 \n",
      "\n",
      "number useful variables / number observations 0.26214833759590794\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 3.717605  Actual loss 0.010349 Actual loss orig 0.010349   \n",
      "error:  0.12461245 \n",
      "\n",
      "number useful variables / number observations 1.0358056265984654\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.235124  Actual loss 0.002579 Actual loss orig 0.002579   \n",
      "error:  0.030187717 \n",
      "\n",
      "number useful variables / number observations 2.3209718670076724\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.030173  Actual loss 0.001840 Actual loss orig 0.001840   \n",
      "error:  0.021785144 \n",
      "\n",
      "number useful variables / number observations 6.4258312020460355\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.035941  Actual loss 0.001608 Actual loss orig 0.001608   \n",
      "error:  0.018543594 \n",
      "\n",
      "number useful variables / number observations 57.64066496163683\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.001141  Actual loss 0.000970 Actual loss orig 0.000970   \n",
      "error:  0.0113896495 \n",
      "\n",
      "number useful variables / number observations 160.00639386189258\n",
      "number observations / number of variables 0.095458984375\n",
      "m,n,nump 1564 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.000333  Actual loss 0.000916 Actual loss orig 0.000916   \n",
      "error:  0.010776096 \n",
      "\n",
      "number useful variables / number observations 0.13183279742765272\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 2.011465  Actual loss 0.006510 Actual loss orig 0.006510  \n",
      "error:  0.0782443 \n",
      "\n",
      "number useful variables / number observations 0.5209003215434084\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.202318  Actual loss 0.001120 Actual loss orig 0.001120  \n",
      "error:  0.012210209 \n",
      "\n",
      "number useful variables / number observations 1.167202572347267\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.054045  Actual loss 0.000782 Actual loss orig 0.000782  \n",
      "error:  0.009190731 \n",
      "\n",
      "number useful variables / number observations 3.2315112540192925\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.030559  Actual loss 0.000593 Actual loss orig 0.000593  \n",
      "error:  0.006911043 \n",
      "\n",
      "number useful variables / number observations 28.987138263665596\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.000487  Actual loss 0.000404 Actual loss orig 0.000404  \n",
      "error:  0.004752719 \n",
      "\n",
      "number useful variables / number observations 80.46623794212219\n",
      "number observations / number of variables 0.1898193359375\n",
      "m,n,nump 3110 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.009413  Actual loss 0.000349 Actual loss orig 0.000349  \n",
      "error:  0.0040663425 \n",
      "\n",
      "number useful variables / number observations 0.0662786938247656\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 410\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.650842  Actual loss 0.003194 Actual loss orig 0.003194  \n",
      "error:  0.036425263 \n",
      "\n",
      "number useful variables / number observations 0.2618816682832202\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.121298  Actual loss 0.000796 Actual loss orig 0.000796  \n",
      "error:  0.010214718 \n",
      "\n",
      "number useful variables / number observations 0.5868089233753637\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.065175  Actual loss 0.000481 Actual loss orig 0.000481  \n",
      "error:  0.0061695334 \n",
      "\n",
      "number useful variables / number observations 1.6246362754607178\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.039098  Actual loss 0.000366 Actual loss orig 0.000366  \n",
      "error:  0.0037890193 \n",
      "\n",
      "number useful variables / number observations 14.573229873908826\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.023828  Actual loss 0.000216 Actual loss orig 0.000216  \n",
      "error:  0.002160506 \n",
      "\n",
      "number useful variables / number observations 40.45425153572583\n",
      "number observations / number of variables 0.3775634765625\n",
      "m,n,nump 6186 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.005249  Actual loss 0.000120 Actual loss orig 0.000120  \n",
      "error:  0.0013506626 \n",
      "\n",
      "number useful variables / number observations 0.03332520523449565\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input provided\n",
      "optimize with adam 0.005\n",
      "610ration 05990    Train loss 0.304709  Actual loss 0.002607 Actual loss orig 0.002607  \n",
      "error:  0.029298972 \n",
      "\n",
      "number useful variables / number observations 0.13167520117044623\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 1620\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "2220ation 05990    Train loss 0.049664  Actual loss 0.000500 Actual loss orig 0.000500  \n",
      "error:  0.0055079754 \n",
      "\n",
      "number useful variables / number observations 0.29504998780785174\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 3630\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "4830ation 05990    Train loss 0.025555  Actual loss 0.000285 Actual loss orig 0.000285  \n",
      "error:  0.003133672 \n",
      "\n",
      "number useful variables / number observations 0.8168739331870275\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 10050\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "13050tion 05990    Train loss 0.010444  Actual loss 0.000148 Actual loss orig 0.000148  \n",
      "error:  0.00199089 \n",
      "\n",
      "number useful variables / number observations 7.327481102170203\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 90150\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "114150ion 05990    Train loss 0.014749  Actual loss 0.000167 Actual loss orig 0.000167  \n",
      "error:  0.0018591225 \n",
      "\n",
      "number useful variables / number observations 20.340567341298872\n",
      "number observations / number of variables 0.75091552734375\n",
      "m,n,nump 12303 16384 250250\n",
      "input provided\n",
      "optimize with adam 0.005\n",
      "315250ion 05990    Train loss 0.009700  Actual loss 0.000114 Actual loss orig 0.000114  \n",
      "error:  0.0012859951 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a small image\n",
    "img_name = \"poster\" # \"F16_GT\"\n",
    "img_path = path + img_name + \".png\"\n",
    "img_pil = Image.open(img_path)\n",
    "img_np = pil_to_np(img_pil)\n",
    "img_np_small = np.array([crop_center(img_np[0],128,128)])\n",
    "img_var = np_to_var(img_np_small).type(dtype)\n",
    "\n",
    "numpoints = 8\n",
    "ms = [ int(100*np.exp(5.5/numpoints*i)) for i in range(numpoints) ] #[100,200,,17000]\n",
    "ks = [10,20,30,50,150,250]\n",
    "\n",
    "err2 = np.zeros((len(ms), len(ks)))\n",
    "\n",
    "numit = 10\n",
    "\n",
    "for q in range(numit):\n",
    "    for j,m in enumerate(ms):\n",
    "        for ell,k in enumerate(ks):\n",
    "        \n",
    "            # generate fixed input\n",
    "            num_channels = [k]*4\n",
    "            ni = get_net_input(num_channels)\n",
    "        \n",
    "            #print(\"number useful variables / number observations\", num_param(net)/m)\n",
    "            print(\"number useful variables / number observations\", (k**2*4 + k) /m)\n",
    "            print(\"number observations / number of variables\", m/n)\n",
    "            print(\"m,n,nump\",m,n,k**2*4 + k)\n",
    "\n",
    "            A = 10*torch.empty(n,m).normal_(0, 1/np.sqrt(m)).type(dtype)\n",
    "            \n",
    "            def forwardm(img):\n",
    "                X = img.view(-1 , np.prod(img.shape) )\n",
    "                return torch.mm(X,A)\n",
    "            \n",
    "            # take measurement of original image\n",
    "            measurement = forwardm(img_var).type(dtype)\n",
    "            out_img_var = dd_recovery(measurement,img_var,num_channels,ni=ni,apply_f=forwardm,num_iter=6000)\n",
    "        \n",
    "            error = snr(out_img_var.data.cpu().numpy()[0] , img_var.data.cpu().numpy()[0])\n",
    "            print(\"error: \", error, \"\\n\")\n",
    "            err2[j,ell] += error/numit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save\n",
    "plt.xscale('log')\n",
    "for i,c in enumerate(['b','r','g','y','b','o']):\n",
    "    plt.plot(ms,err2[:,i],c)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"csf16img_\"+img_name+\".csv\", np.vstack([ np.array(ms) ,np.array(err2).T]).T , delimiter=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
